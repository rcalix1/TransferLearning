{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b10a2e-8bce-4663-8b95-391aa240921b",
   "metadata": {},
   "source": [
    "\n",
    "## Inference Math GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fa87fe-0e9c-4606-8566-f4fadb76f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0400846-9ee7-4570-bd5b-49e3e1b8d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM, AutoModel\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e9345a-7513-4803-85ea-39ad4fb2f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## When testing multiple samples from the dataset, this function allows for batch formatting of the prompts\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['question'])):\n",
    "        text = f'### Question: {example[\"question\"][i]}'\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "899df8ed-08f9-4a0f-a22f-a718e03d6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Quantization config for loading lower precision models\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5abac7-69ed-492d-acf4-4741cc13b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device_map = {\"\": \"cuda:0\"}\n",
    "access_token = None ## PROVIDE OWN HUGGING FACE ACCESS TOKEN HERE\n",
    "\n",
    "## Load gsm8k dataset\n",
    "dataset_name = 'gsm8k'\n",
    "eval_dataset = load_dataset(dataset_name, name='main', split='test')\n",
    "\n",
    "## Define model here. This could be either a HF model on the hub, or a locally saved model\n",
    "#model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "## model_name = 'C:/Users/ITS490/SeniorProject/trl/ppo_flant5_heuristic'\n",
    "model_name = 'sft_gpt2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3336ac39-4916-4ea5-9af4-13fef5030499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Load model using CausalLM for gpt2 and llama2, or Seq2SeqLM for t5. Use line with quantization_config and token for loading llama2\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device_map, trust_remote_code=True)\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device_map, trust_remote_code=True, quantization_config=bnb_config, token=access_token)\n",
    "#model.config.pretraining_tp = 1 \n",
    "\n",
    "\n",
    "### model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=device_map, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c99dc25-7c0e-449f-87c5-449e8c65101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast=True, token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e1f1d5-3a18-4166-9a24-5d340fa5cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create pipeline for generating text. Use text2text-generation for t5, or text-generation for gpt2 or llama2\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n",
    "\n",
    "## generator = pipeline('text2text-generation', model=model_name, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eefcfec8-a598-4883-a1b2-54851ddc9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 128,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d414f-f072-4134-b9a0-297dd0ec71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## For use when testing llama2, change eval_dataset[start:end] to slice out specific parts of the dataset \n",
    "# for i, entry in enumerate(formatting_prompts_func(eval_dataset[1:4])):\n",
    "#     print(eval_dataset[i+1])\n",
    "#     print('\\n')\n",
    "#     eval_tokens = tokenizer.encode(entry)\n",
    "#     eval_response = model.generate(eval_tokens, **generation_kwargs)\n",
    "#     print(tokenizer.decode(eval_response))\n",
    "#     print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb5786a5-41cc-4cb1-97e3-2232bfe0f8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'answer': 'It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nSo the total amount of fabric is 2+1=<<2+1=3>>3 bolts of fabric\\n#### 3'}\n",
      "\n",
      "\n",
      "[{'generated_text': '### Question: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\\n ### Answer: The total cost is 2 * 3 = $<<2*3=6>>6 for white, and 6 * 0.5 = $<<6*0.5=2.5>>2.5 for blue.\\nSo, 8 * 0.5 = $<<8*0.5=6>>6 for white.\\nSo, 6 + 2.5 + 6 = <<6+2.5+6=14>>14 bolts are required for the robe to wear.\\n#### 14 * 0.5 = $<<14*0.5=3.5>>3.5 are needed to buy one set of 3.5 bolts.\\n#### 3.5 * 5 = $<<3.5*5=15>>15 are needed.\\n#### 15 - 2.5 = $<<15-2.5=14>>14 are needed.\\nSo, in total there are 14 - 12 = <<14-12=3>>3 sets of 3.5 and 3.5.\\n#### 3.5 * 3.5 = $<<3.5*3.5=16>>16 needed to buy the robe.\\n#### 16 + 15 = 36 on all\\n#### 36 / 3.'}]\n",
      "\n",
      "\n",
      "\n",
      "{'question': 'Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?', 'answer': 'The cost of the house and repairs came out to 80,000+50,000=$<<80000+50000=130000>>130,000\\nHe increased the value of the house by 80,000*1.5=<<80000*1.5=120000>>120,000\\nSo the new value of the house is 120,000+80,000=$<<120000+80000=200000>>200,000\\nSo he made a profit of 200,000-130,000=$<<200000-130000=70000>>70,000\\n#### 70000'}\n",
      "\n",
      "\n",
      "[{'generated_text': '### Question: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\\n ### Answer: He started at $80,000 and took $50,000 for repair so there were 80*.5 = $<<80*.5=40000>>40000\\nHe sold the house at 50,000 because 40000 is.50000 and.50000 is 60000\\nNow he made $5000 because 40000-500000 are equal\\n#### 50000000 = <<50000000-500000=40000>>40000\\n#### 40000 is equal to $0.25,000 because 40000 x 24000 = $<<40000*24000=8000>>8000\\n#### 8000 is equal to $300000 because 8000/1400 = 80000\\n#### 80000 is equal to $20,000 because 80000 x 20/100 = 100000\\n#### 100000 is equal to $600000 because 10000 - 20000 = $<<10000-20000=200000>>200000\\n####200000 is equal to $30000 because 20000 - 300000 = $600000\\n#### 600,000 is equal to $2000 because 20000 - 20000 = $<<220000-20000=2000>>2000\\n#### 2000 is equal to $11000 because 2000 / 5 = <<2000/5=1000>>1000'}]\n",
      "\n",
      "\n",
      "\n",
      "{'question': 'James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?', 'answer': 'He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*60=<<9*60=540>>540 meters\\n#### 540'}\n",
      "\n",
      "\n",
      "[{'generated_text': \"### Question: James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?\\n ### Answer: He runs it in 4 weeks of the week and uses the same amount per week so he runs at 2*4 = <<4*2=8>>8 miles\\nSo in total he runs in 3+6=<<3+6=9>>9 miles a week\\nIn total he runs 9*.8 = <<9*.8=4>>4 miles a week\\n#### 4+4=10 miles a week\\nSo of the 3 weeks that he runs that he runs he runs a total of 10+3=<<10+3=14>>14 miles a week\\nSo in total he runs a total of 14+8=<<14+8=17>>17 miles a week\\n#### 17+9=<<17+9=33>>33 miles a week\\n#### 33+35=<<33+35=54>>54 miles per week\\n#### 54/week = <<54/*54=18>>18 marathons\\n#### 18\\n#### 18/month = <<18/month=4>>4 months per year.\\nHe decides that he needs to run 4 months a year so he's running that 4/12 = <<4/12=1>>1 year\\n#### 1 year = 1 month\\n\"}]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## For use when testing gpt2 or t5, change eval_dataset[start:end] to slice out specific parts of the dataset \n",
    "for i, entry in enumerate(formatting_prompts_func(eval_dataset[1:4])):\n",
    "     print(eval_dataset[i+1])\n",
    "     print('\\n')\n",
    "     print(generator(entry))\n",
    "     print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f486354-db03-4e9e-8d67-f9ca4ed6814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"### Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? ### Answer: \", 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18'}\n",
      "\n",
      "\n",
      "[{'generated_text': \"### Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? ### Answer:  It costs Janet 16 eggs/day * $2/egg = $<<16*2=48>>48\\nShe sells each batch for $2 per batch * 4 eggs sold/batch = $<<2*4=8>>8\\nEach batch includes 4 eggs. $8 per batch equals <<8*4=48>>48 eggs/batch.\\nIt takes Janet 48 eggs/day * 8 eggs sold/batch = $<<48*8=1024>>1024 in a week\\nSo by weekly amount per batch she makes $256/batch - 24 batch total = $<<256-24=512>>512 every day.\\n#### 512/week = $<<512/week=56>>56 per week\\nEvery week she makes $56/week * 12 days per week = $<<56*12=768>>768\\n#### 768/week = $<<768/week=9>>9 every week\\n#### 956/week * 3 days per week = $<<956*3=1440>>1440\\nIn a week Janet makes $1440/week * 12 days per week = $<<1440*12=1628>>1628\\n#### 1628/week * 4 days/week = $<<1628\"}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## For use when testing a single sample, change eval_dataset[0] to access a specific entry in the dataset\n",
    "query = eval_dataset[0]\n",
    "query['question'] = '### Question: ' + query['question'] + ' ### Answer: '\n",
    "print(query)\n",
    "print('\\n')\n",
    "print(generator(query['question']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a90b6-8673-4920-ac5c-329090a84d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc8977-0e5b-49b1-aa75-46fcd469fd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130ba27-50da-4fdf-a223-025b0e93a7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef94ff-5926-4d89-a7a3-a12338155893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ea709-56a8-48cb-9661-fb59adf89050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742d11f-913e-491c-a4d0-5c51f99dd8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b8ca2-d773-4b90-b58f-28acfe01ceb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5a1c7-5076-4c35-823d-c46547cec043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6ed89-d869-4112-83a4-90e616235271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761feb3-fe20-48a1-8257-6c59d78abb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee6a39-2139-4ba4-a795-d40bb0078970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
