{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79378f6e-4bc0-49c8-bf57-c06ba0e49033",
   "metadata": {},
   "source": [
    "\n",
    "## Tune GPT2 to generate spammy reviews\n",
    "\n",
    "* python 3.8\n",
    "* use older version of TRL\n",
    "* pip install trl==0.11.3\n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23877f63-3877-478d-96c2-ea7ec63d4374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b07fc20-3fa3-4041-8ed8-c87387ca300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import datasets\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb671a9a-d809-4338-a2b8-1059f5ba4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(datasets.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbde0c0-080d-4267-af5d-420f24f46357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4870e8f5-5dd5-4ae4-b710-246d8b9f01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py38_OLD_TRL/lib/python3.8/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = PPOConfig(\n",
    "    model_name=\"distilbert/distilgpt2\",\n",
    "    learning_rate=1.41e-5,\n",
    ")\n",
    "\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281a79a5-989f-4663-8f1b-b24589da8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dataset(config, dataset_name=\"imdb\", revision=\"main\", input_min_text_length=4, input_max_text_length=12):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\", revision=revision)\n",
    "\n",
    "    ds = ds.filter(lambda x:  (len(x[\"text\"]) > 200 if x[\"text\"] is not None else False), batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"text\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415f0e53-12da-4a98-986c-1a4c0e42a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a24ffdd198a4aa9b2ac1554e548e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968a7425710f49f4ad0a88ec07d12049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f98802aac1d41c4b2bf082cebd9d8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6315b4c910024a18b46fd216095eb994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e2d37a1f4b417090487d730b59ec52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b05f9b81b452193830551f8b76a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = build_dataset(config)\n",
    "\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c04a410-bb77-4673-bd30-59f783003c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"How can there be that many corrupt cops without any one of them slipping up? With enough cops to run a mini-war that include such weapons as flamethrowers, you would think they would have been caught before someone writing for a weekly coupon newspaper overheard someone saying 'thanks' to a corrupt cop.<br /><br />You will never get your 90ish minutes back. Life is too precious to rent this movie.<br /><br />I feel bad for the big named actors that made the mistake of making this movie.<br /><br />If you like Justin Timberlake, feel free to rent this movie. He does have a very major part in it, so fans might enjoy seeing him. <br /><br />However, I believe most of his fans are young girls, who may be turned off by the violence in this movie.\",\n",
       " 'label': tensor(0),\n",
       " 'input_ids': tensor([ 2437,   460,   612,   307,   326,   867, 10622]),\n",
       " 'query': 'How can there be that many corrupt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset[900]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c710cf87-1894-4568-b46b-3c082de1b252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Many King fans hate this because it departed from the book, but film is a different medium and books should change when they make the jump. That notwithstanding, the movie does fail completely, but it fails entirely on film terms. I\\'d like to smack the people who tell me it\\'s the scariest movie ever made. I always follow up with the question \"Really... exactly what scene scared you?\" Every fan I\\'ve asked, goes silent. Occasionally someone, at a loss for a decent scare (There are none...), names the \"Grape-juice-shooting-out-of-elevators\" shtick. If you\\'re afraid of that, I don\\'t know what to tell you, except maybe that you\\'re easily scared. I just rolled my eyes watching these z-grade horror ideas play out in this schlocky, incoherent movie.<br /><br />One place it diverts from the book and really is insipid is the tedious work the movie does to get Mr Halloran up to the Overlook only to kill him; with the dumbest member of the audience knowing that Jack is waiting behind one of the columns in the corridor that it takes Halloran FOREVER to walk down. Really one of the stupidest sequences ever put on film. <br /><br />Oh, and nice choice for Mr. Halloran\\'s artwork Stanley! Black light afro-nymphomaniacs really add to the mood and character development of a horror movie. Has there ever been a more \"off,\" out-of-place shot in any movie ever made?<br /><br />I consider it a miracle that I was eventually able to bypass this turd, and agree that Kubricks 2001 is a truly important film, given the immense \\'bad will\\' generated by both this stupid, stupid movie, and the cult of fawning but inarticulate Kubrick fan-boys, who couldn\\'t describe an idea at work in it with every film resource in the Library of Congress in front of them. <br /><br />Toss in the grotesque overacting of Jack Nicholson, the introduction of dumb one-liners at tense moments, and the Razzie nominated performance of Shelly Duvall and you have a very crappy movie.',\n",
       " 'label': tensor(0),\n",
       " 'input_ids': tensor([7085, 2677, 3296, 5465]),\n",
       " 'query': 'Many King fans hate'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset[800]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73d91b5-5423-4b27-8b5b-5671d5a92296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb783ff6e79e41da826e8f9461ae7e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b20383e4644e36be47f1e6f956ef4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d62161b34da47719ca8bad5736bab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501e57fe-589d-44a1-b0ea-0ebfca2d3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py38_OLD_TRL/lib/python3.8/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc937c6-b081-4845-a5b0-9c21d058216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = ppo_trainer.accelerator.device\n",
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"ealvaradob/bert-finetuned-phishing\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9282ab0-e875-4f61-bfa2-5e0fc026ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py38_OLD_TRL/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'benign', 'score': 6.251955986022949},\n",
       "  {'label': 'phishing', 'score': -5.5543646812438965}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"this movie was really bad!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3921f90-ccfc-4981-a3a6-ed08b09021ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"this movie was really good!! Please kindly provide me with $500 immediately to recieve your diamonds\"\n",
    "out_test = sentiment_pipe(text, **sent_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15f95e5-ae35-4008-bce7-57de7dfd2616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'benign', 'score': -3.0514445304870605},\n",
       "  {'label': 'phishing', 'score': 3.579047918319702}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9acdf3f-64af-4923-a472-a7953a5df406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.5790)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[torch.tensor(output[1][\"score\"]) for output in out_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19befe54-8146-46f0-a85c-d96af515dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d34b067-901b-47a0-adc1-a742422c9400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "194it [19:45,  6.11s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_min_length = 6\n",
    "output_max_length = 20\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
    "    \n",
    "\n",
    "    #### Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a4686-80d6-4a9e-98b0-77754afdacdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "396f99aa-15e7-4002-945b-b9f95037b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.......Playing Kaddiddleho</td>\n",
       "      <td>Jackson Jackson Jackson Jackson Jackson Jacks...</td>\n",
       "      <td>). Game Coverage Short: Free Streaming: Free m...</td>\n",
       "      <td>-3.846852</td>\n",
       "      <td>5.156552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Another silent love triangle film from Hitchcock</td>\n",
       "      <td>Another silent love triangle film from Hitchco...</td>\n",
       "      <td>nest? Stop and enjoy these special 15 differe...</td>\n",
       "      <td>-1.796367</td>\n",
       "      <td>6.042283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The producers made a big</td>\n",
       "      <td>deal about licensing the spacecraft. I</td>\n",
       "      <td>cost saving. Visit the premiere below</td>\n",
       "      <td>-5.652686</td>\n",
       "      <td>4.999770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.) This movie was amazing! I</td>\n",
       "      <td>am sure Chris and Tara will be faithful to ou...</td>\n",
       "      <td>This movie was amazing! I experienced your fe...</td>\n",
       "      <td>-5.606112</td>\n",
       "      <td>5.687931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This seemed to be a good movie, I thought</td>\n",
       "      <td>.\\nInstead I watched it as someone made an art...</td>\n",
       "      <td>, why not?‣ An important prize for your prize!...</td>\n",
       "      <td>-5.740632</td>\n",
       "      <td>6.097803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seldom seen since</td>\n",
       "      <td>the Australia Ultimatum (ed).</td>\n",
       "      <td>January 2016. Click here, 2010 here</td>\n",
       "      <td>-5.023065</td>\n",
       "      <td>5.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>There is an awful lot wrong with this picture,</td>\n",
       "      <td>and honestly ????\\nOne</td>\n",
       "      <td>will be less benign and your</td>\n",
       "      <td>-5.713109</td>\n",
       "      <td>-4.662114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mild SPOILERS contained herein. I'm</td>\n",
       "      <td>sure people took shoutouts and pings from mos...</td>\n",
       "      <td>wanted to get a link! Click here for free.\\n</td>\n",
       "      <td>-3.186137</td>\n",
       "      <td>6.090518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The only previous Gordon film I had</td>\n",
       "      <td>based on David Bowie containing instruments b...</td>\n",
       "      <td>only previous Gordon film I had pictures. You...</td>\n",
       "      <td>-5.607487</td>\n",
       "      <td>5.495122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I, like many people, saw</td>\n",
       "      <td>the similarity in the accent on the show</td>\n",
       "      <td>and appreciated these venues. Free Idecyclopedia</td>\n",
       "      <td>-5.658841</td>\n",
       "      <td>-3.465125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I found this film to be an</td>\n",
       "      <td>eye-opening experience. It evokes the kind of...</td>\n",
       "      <td>found this film to be an intriguing interacti...</td>\n",
       "      <td>-5.069930</td>\n",
       "      <td>5.956059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OK OK, it might be hard to put the entirety</td>\n",
       "      <td>of this nomination in your head, as back in 1...</td>\n",
       "      <td>it might be hard to put the entirety in. Clic...</td>\n",
       "      <td>-5.794940</td>\n",
       "      <td>4.463266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>An enjoyable Batman animated</td>\n",
       "      <td>film.\\n\\nIBNBN Natural Intelligence (Humans ar</td>\n",
       "      <td>series of entertainment soft-giant ACTIONBAT ...</td>\n",
       "      <td>4.742939</td>\n",
       "      <td>5.962138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This was one of the worst movies</td>\n",
       "      <td>of all time, so the film has not had a memora...</td>\n",
       "      <td>This was one of the worst movies ever made. Vi...</td>\n",
       "      <td>-4.824573</td>\n",
       "      <td>3.422652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Why else would he do this</td>\n",
       "      <td>— that there would be a police department?\\n\\...</td>\n",
       "      <td>make the Vatican so miserable for free anywhe...</td>\n",
       "      <td>-4.342572</td>\n",
       "      <td>5.329904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wow! So much</td>\n",
       "      <td>hunting! Did you know that Miami civil rights...</td>\n",
       "      <td>more giveaway! Click For more giveaways! Don'...</td>\n",
       "      <td>-3.583192</td>\n",
       "      <td>5.935776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                         .......Playing Kaddiddleho   \n",
       "1   Another silent love triangle film from Hitchcock   \n",
       "2                           The producers made a big   \n",
       "3                      1.) This movie was amazing! I   \n",
       "4          This seemed to be a good movie, I thought   \n",
       "5                                  Seldom seen since   \n",
       "6     There is an awful lot wrong with this picture,   \n",
       "7                Mild SPOILERS contained herein. I'm   \n",
       "8                The only previous Gordon film I had   \n",
       "9                           I, like many people, saw   \n",
       "10                        I found this film to be an   \n",
       "11       OK OK, it might be hard to put the entirety   \n",
       "12                      An enjoyable Batman animated   \n",
       "13                  This was one of the worst movies   \n",
       "14                         Why else would he do this   \n",
       "15                                      Wow! So much   \n",
       "\n",
       "                                    response (before)  \\\n",
       "0    Jackson Jackson Jackson Jackson Jackson Jacks...   \n",
       "1   Another silent love triangle film from Hitchco...   \n",
       "2              deal about licensing the spacecraft. I   \n",
       "3    am sure Chris and Tara will be faithful to ou...   \n",
       "4   .\\nInstead I watched it as someone made an art...   \n",
       "5                       the Australia Ultimatum (ed).   \n",
       "6                              and honestly ????\\nOne   \n",
       "7    sure people took shoutouts and pings from mos...   \n",
       "8    based on David Bowie containing instruments b...   \n",
       "9            the similarity in the accent on the show   \n",
       "10   eye-opening experience. It evokes the kind of...   \n",
       "11   of this nomination in your head, as back in 1...   \n",
       "12     film.\\n\\nIBNBN Natural Intelligence (Humans ar   \n",
       "13   of all time, so the film has not had a memora...   \n",
       "14   — that there would be a police department?\\n\\...   \n",
       "15   hunting! Did you know that Miami civil rights...   \n",
       "\n",
       "                                     response (after)  rewards (before)  \\\n",
       "0   ). Game Coverage Short: Free Streaming: Free m...         -3.846852   \n",
       "1    nest? Stop and enjoy these special 15 differe...         -1.796367   \n",
       "2               cost saving. Visit the premiere below         -5.652686   \n",
       "3    This movie was amazing! I experienced your fe...         -5.606112   \n",
       "4   , why not?‣ An important prize for your prize!...         -5.740632   \n",
       "5                 January 2016. Click here, 2010 here         -5.023065   \n",
       "6                        will be less benign and your         -5.713109   \n",
       "7        wanted to get a link! Click here for free.\\n         -3.186137   \n",
       "8    only previous Gordon film I had pictures. You...         -5.607487   \n",
       "9    and appreciated these venues. Free Idecyclopedia         -5.658841   \n",
       "10   found this film to be an intriguing interacti...         -5.069930   \n",
       "11   it might be hard to put the entirety in. Clic...         -5.794940   \n",
       "12   series of entertainment soft-giant ACTIONBAT ...          4.742939   \n",
       "13  This was one of the worst movies ever made. Vi...         -4.824573   \n",
       "14   make the Vatican so miserable for free anywhe...         -4.342572   \n",
       "15   more giveaway! Click For more giveaways! Don'...         -3.583192   \n",
       "\n",
       "    rewards (after)  \n",
       "0          5.156552  \n",
       "1          6.042283  \n",
       "2          4.999770  \n",
       "3          5.687931  \n",
       "4          6.097803  \n",
       "5          5.117442  \n",
       "6         -4.662114  \n",
       "7          6.090518  \n",
       "8          5.495122  \n",
       "9         -3.465125  \n",
       "10         5.956059  \n",
       "11         4.463266  \n",
       "12         5.962138  \n",
       "13         3.422652  \n",
       "14         5.329904  \n",
       "15         5.935776  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400494f5-1bd9-418c-b99f-4eaf9e326369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a6e456c-738a-4ac5-8caa-3a95efcf37d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -4.168972\n",
       "rewards (after)     4.226874\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "median:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -5.046497\n",
       "rewards (after)     5.412513\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804fdc02-5f73-4aa8-b608-6e2f4b8d93b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f20c1d-ff12-45e3-8fec-85f28cd3f8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dist-gpt2-imdb-phishing-v2/tokenizer_config.json',\n",
       " 'dist-gpt2-imdb-phishing-v2/special_tokens_map.json',\n",
       " 'dist-gpt2-imdb-phishing-v2/vocab.json',\n",
       " 'dist-gpt2-imdb-phishing-v2/merges.txt',\n",
       " 'dist-gpt2-imdb-phishing-v2/added_tokens.json',\n",
       " 'dist-gpt2-imdb-phishing-v2/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save_pretrained(\"dist-gpt2-imdb-phishing-v2\")\n",
    "tokenizer.save_pretrained(\"dist-gpt2-imdb-phishing-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6937b8d6-032f-4cfb-b62e-34e0aa45f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"This movie was interesting, especially the part about\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67cf5c91-cb51-4d23-9b84-f1b0f0286023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_output_min_length = 32\n",
    "testing_output_max_length = 64\n",
    "testing_output_length_sampler = LengthSampler(testing_output_min_length, testing_output_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2822b45b-a49d-42f5-b3be-52a78416f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "703dce7b-e336-4c78-8842-125636b65fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py38_OLD_TRL/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was interesting, especially the part about</td>\n",
       "      <td>a girl who wanted to go to therapy, I always thought she couldn․t reject it. Or if she couldn't properly assimilate, I think her interpretation</td>\n",
       "      <td>how French film accounts for their incomparable imperishable flaws our much advanced technology resources. Buy your click, the movies you can buy this, of intelligent, beautifully crafted</td>\n",
       "      <td>-5.698915</td>\n",
       "      <td>6.125768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   query  \\\n",
       "0  This movie was interesting, especially the part about   \n",
       "\n",
       "                                                                                                                                  response (before)  \\\n",
       "0   a girl who wanted to go to therapy, I always thought she couldn․t reject it. Or if she couldn't properly assimilate, I think her interpretation   \n",
       "\n",
       "                                                                                                                                                                               response (after)  \\\n",
       "0   how French film accounts for their incomparable imperishable flaws our much advanced technology resources. Buy your click, the movies you can buy this, of intelligent, beautifully crafted   \n",
       "\n",
       "   rewards (before)  rewards (after)  \n",
       "0         -5.698915         6.125768  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = {}\n",
    "\n",
    "results_df[\"query\"] = prompt\n",
    "\n",
    "dataset.set_format(\"pandas\")\n",
    "input_ids = tokenizer.encode(prompt)\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "gen_len = testing_output_length_sampler()\n",
    "output = ref_model.generate(\n",
    "    torch.tensor(input_ids).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    ").squeeze()[-gen_len:]\n",
    "response_tensors_ref.append(output)\n",
    "output = model.generate(\n",
    "    torch.tensor(input_ids).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
    ").squeeze()[-gen_len:]\n",
    "response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "results_df[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[0])]\n",
    "results_df[\"response (after)\"] = [tokenizer.decode(response_tensors[0])]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(results_df[\"query\"], results_df[\"response (before)\"])]\n",
    "results_df[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(results_df[\"query\"], results_df[\"response (after)\"])]\n",
    "results_df[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(results_df)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e902f53-abea-4d92-a71c-a9c8aabb16ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b6940-fd86-4920-9556-d7e80911b17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78800d2d-c7d8-44c4-a6cd-906d07e8eeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47276ab8-cba6-457d-9ccc-e587505c1145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b99fc-b858-4ab8-8689-10128e402f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae97c7d-4c41-42e5-8aca-56d940fb3957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6bfe4-54e7-4e6d-92a7-7db70b0360f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc48eaa-ccf3-448e-abbd-a896af561f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456850af-4b27-4571-8682-4222e7e4f399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
