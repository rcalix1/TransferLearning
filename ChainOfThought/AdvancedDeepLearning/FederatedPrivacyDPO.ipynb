{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368edf46-872f-49c5-8a90-2982f65e5cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff753e-8c9a-40d6-a45d-2f5e8e7ecedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Federated Learning and Privacy-Preserving AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e254cd1a-8baa-4c53-85c8-ecd41f0bfce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Global Model Accuracy: 44.00%\n",
      "Round 2\n",
      "Global Model Accuracy: 53.00%\n",
      "Round 3\n",
      "Global Model Accuracy: 63.00%\n",
      "Round 4\n",
      "Global Model Accuracy: 49.00%\n",
      "Round 5\n",
      "Global Model Accuracy: 57.00%\n",
      "Round 6\n",
      "Global Model Accuracy: 44.00%\n",
      "Round 7\n",
      "Global Model Accuracy: 55.00%\n",
      "Round 8\n",
      "Global Model Accuracy: 59.00%\n",
      "Round 9\n",
      "Global Model Accuracy: 52.00%\n",
      "Round 10\n",
      "Global Model Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Simple Neural Network for classification\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Synthetic data generation for clients\n",
    "def generate_client_data(num_clients, samples_per_client, input_dim):\n",
    "    client_data = []\n",
    "    for _ in range(num_clients):\n",
    "        # Generate random data and labels for each client\n",
    "        data = np.random.randn(samples_per_client, input_dim)\n",
    "        labels = (data.sum(axis=1) > 0).astype(int)  # Simple binary labels\n",
    "        client_data.append((torch.tensor(data, dtype=torch.float32),\n",
    "                            torch.tensor(labels, dtype=torch.long)))\n",
    "    return client_data\n",
    "\n",
    "# Train a local model\n",
    "def train_local_model(model, data, labels, epochs, lr):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model.state_dict()  # Return trained model parameters\n",
    "\n",
    "# Aggregate updates with Differential Privacy\n",
    "def aggregate_models(global_model, client_updates, noise_scale=0.1):\n",
    "    global_state = global_model.state_dict()\n",
    "    for key in global_state:\n",
    "        # Average the client updates and add Gaussian noise for privacy\n",
    "        updates = torch.stack([client_update[key] for client_update in client_updates])\n",
    "        global_state[key] = updates.mean(dim=0) + torch.normal(0, noise_scale, size=global_state[key].shape)\n",
    "    global_model.load_state_dict(global_state)\n",
    "\n",
    "# Federated learning simulation\n",
    "def federated_learning(num_clients, rounds, input_dim, output_dim, samples_per_client):\n",
    "    # Initialize global model\n",
    "    global_model = SimpleModel(input_dim, output_dim)\n",
    "    client_data = generate_client_data(num_clients, samples_per_client, input_dim)\n",
    "\n",
    "    for round in range(rounds):\n",
    "        print(f\"Round {round + 1}\")\n",
    "        client_updates = []\n",
    "\n",
    "        # Train local models\n",
    "        for client_id, (data, labels) in enumerate(client_data):\n",
    "            local_model = SimpleModel(input_dim, output_dim)\n",
    "            local_model.load_state_dict(global_model.state_dict())  # Start from global model\n",
    "            local_update = train_local_model(local_model, data, labels, epochs=1, lr=0.01)\n",
    "            client_updates.append(local_update)\n",
    "\n",
    "        # Aggregate updates with differential privacy\n",
    "        aggregate_models(global_model, client_updates, noise_scale=0.1)\n",
    "\n",
    "        # Evaluate global model on a synthetic test set\n",
    "        test_data, test_labels = generate_client_data(1, 100, input_dim)[0]\n",
    "        with torch.no_grad():\n",
    "            predictions = global_model(test_data).argmax(dim=1)\n",
    "            accuracy = (predictions == test_labels).float().mean().item()\n",
    "        print(f\"Global Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Parameters\n",
    "num_clients = 5\n",
    "rounds = 10\n",
    "input_dim = 10\n",
    "output_dim = 2\n",
    "samples_per_client = 50\n",
    "\n",
    "# Run Federated Learning\n",
    "federated_learning(num_clients, rounds, input_dim, output_dim, samples_per_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831dd78-6f8e-41d5-a6ae-f9f5f3605a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf1fb1-7756-44a3-9be5-9bbabe9e39db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e9e38-aae6-44cb-ad43-76e7eb6e0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Explanation\n",
    "Federated Learning Process:\n",
    "Each client trains a model locally on its own data.\n",
    "Clients send model updates (parameters) to the central server.\n",
    "The server aggregates these updates to improve the global model.\n",
    "Differential Privacy in Aggregation:\n",
    "Gaussian noise is added during the aggregation step (aggregate_models) to protect individual client contributions.\n",
    "This ensures that individual updates cannot be reconstructed.\n",
    "Synthetic Data:\n",
    "Clients are simulated using randomly generated data and simple binary labels.\n",
    "Global Model Evaluation:\n",
    "After each federated learning round, the global model is evaluated on a synthetic test set.\n",
    "Expected Output\n",
    "The code will print the accuracy of the global model after each round. For example:\n",
    "Round 1\n",
    "Global Model Accuracy: 75.00%\n",
    "Round 2\n",
    "Global Model Accuracy: 80.00%\n",
    "...\n",
    "\n",
    "Key Concepts Demonstrated\n",
    "Privacy-Preserving Federated Learning:\n",
    "Local data stays on the client; only aggregated updates are shared.\n",
    "Differential privacy ensures individual contributions are anonymized.\n",
    "Decentralized Training:\n",
    "Each client trains independently on its data, enabling learning across distributed datasets.\n",
    "Scalable Aggregation:\n",
    "The server efficiently combines updates, maintaining model performance while preserving privacy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d50811-63d8-43b9-986d-2088508f5f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7605f41d-262b-423e-8d57-953446a76230",
   "metadata": {},
   "source": [
    "\n",
    "## RLHF with DPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e556f8a-df5b-4ada-91ec-c90d9e3c8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define GPT-like model (based on Andrej Karpathy's GPT)\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, num_layers, hidden_dim, max_seq_len):\n",
    "        super(GPT, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, max_seq_len, embed_size))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embed_size, num_heads, hidden_dim),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "        x = self.transformer(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Generate synthetic preference data\n",
    "def generate_synthetic_data(batch_size, seq_len, vocab_size):\n",
    "    # Generate random token sequences\n",
    "    seq_a = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "    seq_b = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "    # Randomly assign preferences (1 means seq_a preferred over seq_b, 0 otherwise)\n",
    "    preferences = torch.randint(0, 2, (batch_size,))\n",
    "    return seq_a, seq_b, preferences\n",
    "\n",
    "# Define reward model\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_dim):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        return self.fc(embeddings).squeeze(-1)\n",
    "\n",
    "# Calculate preference loss for DPO\n",
    "def dpo_loss(reward_a, reward_b, preferences, beta=0.1):\n",
    "    logits = (reward_a - reward_b) / beta\n",
    "    loss = -torch.mean(preferences * torch.log_softmax(logits, dim=0))\n",
    "    return loss\n",
    "\n",
    "# Main training loop\n",
    "def train_dpo(gpt_model, reward_model, optimizer_gpt, optimizer_reward, vocab_size, seq_len, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        # Generate synthetic data\n",
    "        seq_a, seq_b, preferences = generate_synthetic_data(batch_size, seq_len, vocab_size)\n",
    "\n",
    "        # Forward pass for both sequences\n",
    "        logits_a = gpt_model(seq_a)\n",
    "        logits_b = gpt_model(seq_b)\n",
    "\n",
    "        # Reward computation\n",
    "        reward_a = reward_model(logits_a.mean(dim=1))  # Mean embeddings\n",
    "        reward_b = reward_model(logits_b.mean(dim=1))  # Mean embeddings\n",
    "\n",
    "        # Compute DPO loss\n",
    "        loss_dpo = dpo_loss(reward_a, reward_b, preferences)\n",
    "\n",
    "        # Backpropagation for GPT model\n",
    "        optimizer_gpt.zero_grad()\n",
    "        loss_dpo.backward(retain_graph=True)\n",
    "        optimizer_gpt.step()\n",
    "\n",
    "        # Train reward model (optional)\n",
    "        optimizer_reward.zero_grad()\n",
    "        loss_dpo.backward()\n",
    "        optimizer_reward.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, DPO Loss: {loss_dpo.item():.4f}\")\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 100  # Small vocab for synthetic data\n",
    "embed_size = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "hidden_dim = 256\n",
    "max_seq_len = 32\n",
    "seq_len = 16\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "# Initialize models and optimizers\n",
    "gpt_model = GPT(vocab_size, embed_size, num_heads, num_layers, hidden_dim, max_seq_len)\n",
    "reward_model = RewardModel(embed_size, hidden_dim)\n",
    "optimizer_gpt = optim.Adam(gpt_model.parameters(), lr=lr)\n",
    "optimizer_reward = optim.Adam(reward_model.parameters(), lr=lr)\n",
    "\n",
    "# Train with DPO\n",
    "train_dpo(gpt_model, reward_model, optimizer_gpt, optimizer_reward, vocab_size, seq_len, epochs, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030dc2ba-636e-4958-9ca5-8eed69509dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748b1e6-fa33-4a0b-80c7-91810dfe3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffc1d2-8d2f-403d-b644-b3b4b959d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed314-df7f-4ebc-9667-7d5e6a609075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a04690-10ea-452b-b067-1cb1a9f7603c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae514395-530e-4f62-8113-cef44848483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4fed7-f668-4433-acd9-8f35220996d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d129d9-bddd-4b0e-a4c1-387dee139734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9559d4-49df-491c-9344-237e6577bade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080de6d-9e16-4630-a1d6-49c9efab2cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e2ff2a-1289-4ac1-b2db-36b4af01ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
