{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch", "import torch.nn as nn", "", "class ExpertModel(nn.Module):", "    def __init__(self, vocab_size, embed_size, num_heads, num_layers, hidden_dim):", "        super(ExpertModel, self).__init__()", "        self.embedding = nn.Embedding(vocab_size, embed_size)", "        self.positional_encoding = nn.Parameter(torch.randn(1, 100, embed_size))", "        self.transformer = nn.TransformerEncoder(", "            nn.TransformerEncoderLayer(embed_size, num_heads, hidden_dim),", "            num_layers", "        )", "        self.fc = nn.Linear(embed_size, vocab_size)", "", "    def forward(self, x):", "        x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]", "        return self.fc(self.transformer(x)[:, -1, :])", "", "vocab_size = 50", "expert_1 = ExpertModel(vocab_size, embed_size=16, num_heads=2, num_layers=2, hidden_dim=64)", "expert_2 = ExpertModel(vocab_size, embed_size=16, num_heads=2, num_layers=2, hidden_dim=64)", "", "def route(task_type, input_tensor):", "    if task_type == \"task_1\":", "        return expert_1(input_tensor)", "    elif task_type == \"task_2\":", "        return expert_2(input_tensor)", "    else:", "        raise ValueError(\"Unknown task type\")", "", "dummy_input = torch.randint(0, vocab_size, (1, 10))", "task_type = \"task_1\"", "output = route(task_type, dummy_input)", "print(f\"Output Shape: {output.shape}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}