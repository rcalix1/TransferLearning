{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80e2b5-2fe5-4eb2-aad8-de323135f5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5379ea-d985-46ea-ae18-4ff2ad163b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbf4c1-1360-481b-be79-c8fff727df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import random\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Freeze most of the LLM weights (optional, for efficiency)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a simple linear head for reinforcement learning\n",
    "class AgentLLM(nn.Module):\n",
    "    def __init__(self, gpt_model, num_actions):\n",
    "        super(AgentLLM, self).__init__()\n",
    "        self.gpt = gpt_model\n",
    "        self.fc = nn.Linear(self.gpt.config.hidden_size, num_actions)  # Map LLM output to actions\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        gpt_outputs = self.gpt(input_ids, return_dict=True).last_hidden_state\n",
    "        action_logits = self.fc(gpt_outputs[:, -1, :])  # Use the last token's hidden state\n",
    "        return action_logits\n",
    "\n",
    "# Environment simulation for training and evaluation\n",
    "class SimpleEnvironment:\n",
    "    def __init__(self):\n",
    "        self.goal = \"Solve the puzzle\"\n",
    "        self.actions = [\n",
    "            \"Plan next step\",\n",
    "            \"Analyze the puzzle\",\n",
    "            \"Solve sub-problems\",\n",
    "        ]\n",
    "        self.correct_sequence = [\"Plan next step\", \"Analyze the puzzle\", \"Solve sub-problems\"]\n",
    "        self.state_index = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.state_index < len(self.correct_sequence) and action == self.correct_sequence[self.state_index]:\n",
    "            self.state_index += 1\n",
    "            if self.state_index == len(self.correct_sequence):\n",
    "                return \"Goal reached!\", 1.0, True\n",
    "            return f\"Action '{action}' was correct.\", 0.5, False\n",
    "        else:\n",
    "            return f\"Action '{action}' was incorrect.\", -0.1, False\n",
    "\n",
    "# Training loop for the LLM-based agent\n",
    "def train_agent(agent, env, optimizer, num_episodes=100):\n",
    "    agent.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = \"Start\"\n",
    "        env.state_index = 0\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Query LLM for reasoning\n",
    "            prompt = f\"The current state is '{state}'. The goal is '{env.goal}'. What should I do next?\"\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "            \n",
    "            # Get action logits from the agent\n",
    "            action_logits = agent(input_ids)\n",
    "            action_probs = torch.softmax(action_logits, dim=-1)\n",
    "            action_idx = torch.argmax(action_probs).item()\n",
    "\n",
    "            # Map index to action\n",
    "            action = env.actions[action_idx]\n",
    "\n",
    "            # Interact with the environment\n",
    "            state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Compute loss and update the model\n",
    "            target = torch.tensor([action_idx], dtype=torch.long)  # Correct action index\n",
    "            loss = loss_fn(action_logits, target.unsqueeze(0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return total_rewards\n",
    "\n",
    "# Evaluate the trained agent\n",
    "def evaluate_agent(agent, env):\n",
    "    agent.eval()\n",
    "    state = \"Start\"\n",
    "    env.state_index = 0\n",
    "    done = False\n",
    "\n",
    "    print(\"\\n--- Evaluation ---\")\n",
    "    while not done:\n",
    "        prompt = f\"The current state is '{state}'. The goal is '{env.goal}'. What should I do next?\"\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action_logits = agent(input_ids)\n",
    "            action_idx = torch.argmax(action_logits).item()\n",
    "        \n",
    "        action = env.actions[action_idx]\n",
    "        print(f\"Agent Action: {action}\")\n",
    "\n",
    "        state, reward, done = env.step(action)\n",
    "        print(f\"Environment Response: {state}\")\n",
    "\n",
    "# Initialize environment, agent, and optimizer\n",
    "env = SimpleEnvironment()\n",
    "num_actions = len(env.actions)\n",
    "\n",
    "agent = AgentLLM(model, num_actions)\n",
    "optimizer = optim.Adam(agent.fc.parameters(), lr=0.001)  # Train only the new head\n",
    "\n",
    "# Train the agent\n",
    "train_agent(agent, env, num_episodes=50)\n",
    "\n",
    "# Evaluate the trained agent\n",
    "evaluate_agent(agent, env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814fd92-87ac-45a5-9bef-48ab3ff9cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5834d-249b-4f8e-8d0f-a1c314a2fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load GPT-2 model weights from PyTorch Hub\n",
    "gpt2_model = torch.hub.load('pytorch/fairseq', 'transformer_lm.gpt2.small')\n",
    "\n",
    "# GPT-2 Configuration\n",
    "class GPT2(nn.Module):\n",
    "    def __init__(self, gpt2_model, num_actions):\n",
    "        super(GPT2, self).__init__()\n",
    "        self.gpt2 = gpt2_model\n",
    "        self.fc = nn.Linear(self.gpt2.encoder.embed_tokens.embedding_dim, num_actions)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Pass input through GPT-2\n",
    "        gpt2_output = self.gpt2(input_ids)\n",
    "        last_hidden_state = gpt2_output[0]  # Get the last layer hidden state\n",
    "        action_logits = self.fc(last_hidden_state[:, -1, :])  # Only use the last token's embedding\n",
    "        return action_logits\n",
    "\n",
    "# Environment simulation for training and evaluation\n",
    "class SimpleEnvironment:\n",
    "    def __init__(self):\n",
    "        self.goal = \"Solve the puzzle\"\n",
    "        self.actions = [\n",
    "            \"Plan next step\",\n",
    "            \"Analyze the puzzle\",\n",
    "            \"Solve sub-problems\",\n",
    "        ]\n",
    "        self.correct_sequence = [\"Plan next step\", \"Analyze the puzzle\", \"Solve sub-problems\"]\n",
    "        self.state_index = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.state_index < len(self.correct_sequence) and action == self.correct_sequence[self.state_index]:\n",
    "            self.state_index += 1\n",
    "            if self.state_index == len(self.correct_sequence):\n",
    "                return \"Goal reached!\", 1.0, True\n",
    "            return f\"Action '{action}' was correct.\", 0.5, False\n",
    "        else:\n",
    "            return f\"Action '{action}' was incorrect.\", -0.1, False\n",
    "\n",
    "# Training loop for the LLM-based agent\n",
    "def train_agent(agent, env, optimizer, num_episodes=100):\n",
    "    agent.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = \"Start\"\n",
    "        env.state_index = 0\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Query LLM for reasoning\n",
    "            prompt = f\"The current state is '{state}'. The goal is '{env.goal}'. What should I do next?\"\n",
    "            input_ids = torch.tensor([gpt2_model.encode(prompt)], dtype=torch.long)\n",
    "            \n",
    "            # Get action logits from the agent\n",
    "            action_logits = agent(input_ids)\n",
    "            action_probs = torch.softmax(action_logits, dim=-1)\n",
    "            action_idx = torch.argmax(action_probs).item()\n",
    "\n",
    "            # Map index to action\n",
    "            action = env.actions[action_idx]\n",
    "\n",
    "            # Interact with the environment\n",
    "            state, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Compute loss and update the model\n",
    "            target = torch.tensor([action_idx], dtype=torch.long)  # Correct action index\n",
    "            loss = loss_fn(action_logits, target.unsqueeze(0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return total_rewards\n",
    "\n",
    "# Evaluate the trained agent\n",
    "def evaluate_agent(agent, env):\n",
    "    agent.eval()\n",
    "    state = \"Start\"\n",
    "    env.state_index = 0\n",
    "    done = False\n",
    "\n",
    "    print(\"\\n--- Evaluation ---\")\n",
    "    while not done:\n",
    "        prompt = f\"The current state is '{state}'. The goal is '{env.goal}'. What should I do next?\"\n",
    "        input_ids = torch.tensor([gpt2_model.encode(prompt)], dtype=torch.long)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action_logits = agent(input_ids)\n",
    "            action_idx = torch.argmax(action_logits).item()\n",
    "        \n",
    "        action = env.actions[action_idx]\n",
    "        print(f\"Agent Action: {action}\")\n",
    "\n",
    "        state, reward, done = env.step(action)\n",
    "        print(f\"Environment Response: {state}\")\n",
    "\n",
    "# Initialize environment, agent, and optimizer\n",
    "env = SimpleEnvironment()\n",
    "num_actions = len(env.actions)\n",
    "\n",
    "agent = GPT2(gpt2_model, num_actions)\n",
    "optimizer = optim.Adam(agent.fc.parameters(), lr=0.001)  # Train only the new head\n",
    "\n",
    "# Train the agent\n",
    "train_agent(agent, env, num_episodes=50)\n",
    "\n",
    "# Evaluate the trained agent\n",
    "evaluate_agent(agent, env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b3c0d-f389-454b-9c96-d89d67ec3908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7eeb69-029c-4d07-a15e-d685d528f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPT Architecture (compatible with pre-trained weights)\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_embd, n_layer, n_head):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(n_embd, n_head) for _ in range(n_layer)\n",
    "        ])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.size()\n",
    "        tok_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        self.attn = CausalSelfAttention(n_embd, n_head)\n",
    "        self.ff = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = n_embd // n_head\n",
    "        self.query = nn.Linear(n_embd, n_embd)\n",
    "        self.key = nn.Linear(n_embd, n_embd)\n",
    "        self.value = nn.Linear(n_embd, n_embd)\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(1024, 1024)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q = self.query(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attn = attn.masked_fill(self.mask[:T, :T] == 0, float(\"-inf\"))\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        out = attn @ v\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        return self.proj(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * n_embd, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Load GPT-2 Pre-Trained Weights from PyTorch Hub\n",
    "gpt2_model = torch.hub.load(\"pytorch/fairseq\", \"transformer_lm.gpt2.small\")\n",
    "gpt2_weights = gpt2_model.state_dict()\n",
    "\n",
    "# Initialize Custom GPT Model\n",
    "vocab_size = gpt2_weights[\"encoder.embed_tokens.weight\"].shape[0]\n",
    "block_size = 1024\n",
    "n_embd = 768\n",
    "n_layer = 12\n",
    "n_head = 12\n",
    "\n",
    "model = GPT(vocab_size, block_size, n_embd, n_layer, n_head)\n",
    "\n",
    "# Map GPT-2 weights to custom GPT model\n",
    "model.token_embedding.weight.data = gpt2_weights[\"encoder.embed_tokens.weight\"]\n",
    "model.position_embedding.weight.data = gpt2_weights[\"encoder.embed_positions.weight\"]\n",
    "\n",
    "# Fine-Tuning\n",
    "def fine_tune(model, data, epochs=3, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in data:\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, vocab_size), y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Example data\n",
    "data = [  # Dummy data: sequence input and target\n",
    "    (torch.randint(0, vocab_size, (4, block_size)), torch.randint(0, vocab_size, (4, block_size)))\n",
    "]\n",
    "\n",
    "# Fine-Tune\n",
    "fine_tune(model, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78163fa-8b27-443a-8313-b3069cad5f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a32591-8872-415d-8b29-d189a3b6a55f",
   "metadata": {},
   "source": [
    "\n",
    "## In C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336059a0-1afa-4824-864e-7ce7feb27c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## quantization optional \n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421f967-07c4-4b11-b503-633c2b60144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.hub.load('pytorch/fairseq', 'transformer_lm.gpt2.small')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7eb8b3-f92a-437f-b114-17a30f26c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save GPT-2 weights\n",
    "torch.save(model.state_dict(), \"gpt2_weights.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f45135-f08d-47ee-9329-5ad83f7e4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Save specific parameters in binary format\n",
    "\n",
    "with open(\"gpt2_weights.bin\", \"wb\") as f:\n",
    "    for param_tensor in model.state_dict():\n",
    "        f.write(model.state_dict()[param_tensor].numpy().tobytes())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d518a-8d97-469c-9175-a9aaa3802fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "// Matrix multiplication\n",
    "void matmul(float* A, float* B, float* C, int M, int N, int K) {\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        for (int j = 0; j < K; j++) {\n",
    "            C[i * K + j] = 0;\n",
    "            for (int k = 0; k < N; k++) {\n",
    "                C[i * K + j] += A[i * N + k] * B[k * K + j];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Simplified forward pass\n",
    "void forward(float* input, float* weights, float* output, int input_dim, int output_dim) {\n",
    "    matmul(input, weights, output, 1, input_dim, output_dim);  // Single layer example\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int input_dim = 768;    // GPT hidden size\n",
    "    int output_dim = 50257; // Vocabulary size\n",
    "\n",
    "    // Load weights\n",
    "    FILE* weight_file = fopen(\"gpt2_weights.bin\", \"rb\");\n",
    "    float* weights = malloc(input_dim * output_dim * sizeof(float));\n",
    "    fread(weights, sizeof(float), input_dim * output_dim, weight_file);\n",
    "    fclose(weight_file);\n",
    "\n",
    "    // Input vector\n",
    "    float input[input_dim];\n",
    "    for (int i = 0; i < input_dim; i++) input[i] = 1.0f;  // Example input\n",
    "\n",
    "    // Output vector\n",
    "    float output[output_dim];\n",
    "    forward(input, weights, output, input_dim, output_dim);\n",
    "\n",
    "    // Print top predictions\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"Output[%d]: %f\\n\", i, output[i]);\n",
    "    }\n",
    "\n",
    "    free(weights);\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c49db-501d-4f16-be91-fc6b6acaab8a",
   "metadata": {},
   "source": [
    "\n",
    "## faster c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d06cc-6c09-4bb4-9f4a-cfc9e7b089ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cblas.h>\n",
    "\n",
    "// Matrix multiplication using BLAS\n",
    "void matmul(float* A, float* B, float* C, int M, int N, int K) {\n",
    "    cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans,\n",
    "                M, K, N, 1.0, A, N, B, K, 0.0, C, K);\n",
    "}\n",
    "\n",
    "// Simplified feedforward pass of a single layer\n",
    "void feedforward(float* input, float* weights, float* output, int input_dim, int output_dim) {\n",
    "    matmul(input, weights, output, 1, input_dim, output_dim);\n",
    "}\n",
    "\n",
    "// Load weights from a binary file\n",
    "float* load_weights(const char* filename, int size) {\n",
    "    FILE* file = fopen(filename, \"rb\");\n",
    "    if (!file) {\n",
    "        printf(\"Error: Unable to open file %s\\\\n\", filename);\n",
    "        exit(1);\n",
    "    }\n",
    "    float* weights = malloc(size * sizeof(float));\n",
    "    fread(weights, sizeof(float), size, file);\n",
    "    fclose(file);\n",
    "    return weights;\n",
    "}\n",
    "\n",
    "// Simple softmax function\n",
    "void softmax(float* logits, int size) {\n",
    "    float max = logits[0];\n",
    "    for (int i = 1; i < size; i++) {\n",
    "        if (logits[i] > max) max = logits[i];\n",
    "    }\n",
    "    float sum = 0.0;\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        logits[i] = expf(logits[i] - max);  // Prevent overflow\n",
    "        sum += logits[i];\n",
    "    }\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        logits[i] /= sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Model dimensions\n",
    "    int input_dim = 768;    // GPT hidden size\n",
    "    int output_dim = 50257; // GPT vocabulary size\n",
    "\n",
    "    // Load pre-trained weights (e.g., from PyTorch or custom binary format)\n",
    "    float* weights = load_weights(\"gpt2_weights.bin\", input_dim * output_dim);\n",
    "\n",
    "    // Input vector (example input, normally generated from embeddings)\n",
    "    float input[input_dim];\n",
    "    for (int i = 0; i < input_dim; i++) input[i] = 1.0f;  // Example input\n",
    "\n",
    "    // Output vector\n",
    "    float* output = malloc(output_dim * sizeof(float));\n",
    "\n",
    "    // Perform a forward pass\n",
    "    feedforward(input, weights, output, input_dim, output_dim);\n",
    "\n",
    "    // Apply softmax to logits\n",
    "    softmax(output, output_dim);\n",
    "\n",
    "    // Print top predictions\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"Logit[%d]: %f\\\\n\", i, output[i]);\n",
    "    }\n",
    "\n",
    "    // Free memory\n",
    "    free(weights);\n",
    "    free(output);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ae1c7-c2ae-4961-a1ae-d28bd396c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sudo apt-get install libopenblas-dev\n",
    "\n",
    "gcc -o gpt_optimized gpt_optimized.c -lopenblas -lm\n",
    "\n",
    "./gpt_optimized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec3a73-0385-4205-9c6c-d6d01ad3225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Save weights in binary format\n",
    "model = torch.load(\"gpt2_model.pth\")\n",
    "weights = model[\"decoder\"][\"linear.weight\"].cpu().numpy()\n",
    "with open(\"gpt2_weights.bin\", \"wb\") as f:\n",
    "    f.write(weights.tobytes())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14acffa-b648-42a7-97fe-f4a9af1be8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Logit[0]: 0.123456\n",
    "Logit[1]: 0.098765\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfc58c-caae-4ccf-86b7-daad7cee66ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08b632-cca0-41b6-9ce9-1b2226524a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a9b70-6344-4e15-8597-e6af63651ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2ace3-44cf-4928-9d04-e45305808021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d6cd5-c5c3-4cfc-bcab-b52a7cacb643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a626e-b812-4c31-8b2c-64c780c9660f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
