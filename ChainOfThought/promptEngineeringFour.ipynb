{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1015a910-1740-45ff-82e7-1a158e19d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "## from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f5d8-8bd3-4daf-aa83-2defa71d3b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648500ca-b5b9-4cf4-b619-f3fcbdd258d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddfd182-7e8c-4241-88df-fc42988bb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Random data distribution (e.g., probabilities of events)\n",
    "data_distribution = [0.2, 0.5, 0.3]\n",
    "\n",
    "# Calculate Shannon entropy\n",
    "shannon_entropy = entropy(data_distribution, base=2)  # Base 2 for bits\n",
    "print(f\"Shannon Entropy: {shannon_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f8e62-3014-4eef-a0a2-98b13575bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulated network traffic data (packet sizes in bytes)\n",
    "network_traffic = [40, 40, 45, 50, 55, 500, 45, 50, 60, 55]  # Anomalous 500\n",
    "\n",
    "# Calculate entropy\n",
    "def calculate_entropy(data):\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    probabilities = counts / len(data)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "entropy_before = calculate_entropy(network_traffic[:-1])  # Normal traffic\n",
    "entropy_after = calculate_entropy(network_traffic)  # With anomaly\n",
    "\n",
    "print(f\"Entropy before anomaly: {entropy_before:.4f}\")\n",
    "print(f\"Entropy after anomaly: {entropy_after:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f39569-a14e-47b8-9c3e-0f6ba1f4fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Simulated dataset (features and labels)\n",
    "X = np.array([[1, 0], [0, 1], [1, 1], [0, 0], [1, 0]])  # Features\n",
    "y = np.array([0, 1, 1, 0, 0])  # Labels\n",
    "\n",
    "# Calculate mutual information\n",
    "mi = mutual_info_classif(X, y, discrete_features=True)\n",
    "print(f\"Mutual Information between features and labels: {mi}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997c906-194b-442f-ae90-2100a2ea9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate key distribution (probabilities of each key being used)\n",
    "key_distribution = [0.7, 0.2, 0.1]\n",
    "\n",
    "# Calculate entropy of the key distribution\n",
    "key_entropy = -np.sum([p * np.log2(p) for p in key_distribution])\n",
    "print(f\"Entropy of key distribution: {key_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d38ed-fc57-4fca-9f5a-005a9477e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_file_entropy(file_data):\n",
    "    \"\"\"Calculate Shannon entropy of a binary file.\"\"\"\n",
    "    byte_counts = np.bincount(np.frombuffer(file_data, dtype=np.uint8), minlength=256)\n",
    "    probabilities = byte_counts / len(file_data)\n",
    "    probabilities = probabilities[probabilities > 0]  # Filter non-zero probabilities\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Simulated binary file (random bytes)\n",
    "file_data = np.random.randint(0, 256, size=1024, dtype=np.uint8).tobytes()\n",
    "\n",
    "file_entropy = calculate_file_entropy(file_data)\n",
    "print(f\"File Entropy: {file_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5798a1e-6b4e-46c3-b79c-890f672889fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Simulated network traffic distributions (normal vs. anomaly)\n",
    "normal_traffic = [0.4, 0.3, 0.2, 0.1]\n",
    "anomalous_traffic = [0.1, 0.3, 0.4, 0.2]\n",
    "\n",
    "# Calculate KL divergence\n",
    "kl_divergence = entropy(normal_traffic, anomalous_traffic)\n",
    "print(f\"KL Divergence: {kl_divergence:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7e042-0be9-49ac-a035-ebc226094a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data and calculate entropy over a sliding window\n",
    "data = np.random.randint(1, 100, 100)\n",
    "window_size = 10\n",
    "entropies = [calculate_entropy(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "\n",
    "# Plot entropy over time\n",
    "plt.plot(entropies)\n",
    "plt.title(\"Entropy Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf77b89-49eb-4d35-a26c-a83986513ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated risk probabilities for a set of cyber threats\n",
    "threat_probabilities = [0.1, 0.2, 0.4, 0.3]\n",
    "\n",
    "# Calculate entropy as a measure of uncertainty in threat likelihood\n",
    "risk_entropy = -np.sum([p * np.log2(p) for p in threat_probabilities])\n",
    "print(f\"Risk Entropy: {risk_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9750707-fc7c-4906-ab5b-c1a8e83ccc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated impact scores for cyber threats\n",
    "threat_impacts = [0.8, 0.5, 0.9, 0.6]\n",
    "expected_risks = [p * i for p, i in zip(threat_probabilities, threat_impacts)]\n",
    "\n",
    "# Select the threat with the highest expected risk\n",
    "highest_risk_index = np.argmax(expected_risks)\n",
    "print(f\"Threat with highest expected risk: {highest_risk_index}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e8fc7-1b53-4afa-9849-519416095d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probability distributions of model predictions\n",
    "original_distribution = [0.7, 0.2, 0.1]\n",
    "adversarial_distribution = [0.4, 0.4, 0.2]\n",
    "\n",
    "# KL Divergence to measure the effect of the adversarial attack\n",
    "kl_div = entropy(original_distribution, adversarial_distribution)\n",
    "print(f\"KL Divergence between original and adversarial: {kl_div:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a2a8a-f6a3-48ed-acc5-27fb3443c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quantum entropy calculation (von Neumann entropy)\n",
    "def quantum_entropy(density_matrix):\n",
    "    \"\"\"Calculate von Neumann entropy from a density matrix.\"\"\"\n",
    "    eigenvalues = np.linalg.eigvals(density_matrix)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]  # Filter out zero eigenvalues\n",
    "    return -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "\n",
    "# Example density matrix (random Hermitian positive-definite matrix)\n",
    "density_matrix = np.array([[0.5, 0.1], [0.1, 0.5]])\n",
    "quantum_entropy_value = quantum_entropy(density_matrix)\n",
    "print(f\"Quantum Entropy: {quantum_entropy_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a7766-e145-4a96-ac3d-3be37f721115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated attack probabilities and entropy changes\n",
    "attack_probabilities = [0.2, 0.5, 0.3]  # Before detection system\n",
    "updated_probabilities = [0.1, 0.7, 0.2]  # After detection system\n",
    "\n",
    "# Calculate information gained by the system\n",
    "initial_entropy = entropy(attack_probabilities, base=2)\n",
    "updated_entropy = entropy(updated_probabilities, base=2)\n",
    "information_gain = initial_entropy - updated_entropy\n",
    "\n",
    "print(f\"Initial Entropy: {initial_entropy:.4f} bits\")\n",
    "print(f\"Updated Entropy: {updated_entropy:.4f} bits\")\n",
    "print(f\"Information Gain: {information_gain:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4e301-ca34-4b5b-a3c1-d3a5c63bade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probabilities of data exposure in different scenarios\n",
    "exposure_probabilities = [0.6, 0.3, 0.1]\n",
    "\n",
    "# Calculate entropy to quantify uncertainty about data exposure\n",
    "exposure_entropy = -np.sum([p * np.log2(p) for p in exposure_probabilities])\n",
    "print(f\"Data Exposure Entropy: {exposure_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ece91-9f81-429c-9470-f1b26cf2e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Adding Laplace noise for differential privacy\n",
    "def add_laplace_noise(value, sensitivity, epsilon):\n",
    "    \"\"\"Add Laplace noise to a value for differential privacy.\"\"\"\n",
    "    noise = np.random.laplace(0, sensitivity / epsilon)\n",
    "    return value + noise\n",
    "\n",
    "# Original value and sensitivity\n",
    "original_value = 100  # e.g., a count of events\n",
    "sensitivity = 1\n",
    "epsilon = 0.5\n",
    "\n",
    "noisy_value = add_laplace_noise(original_value, sensitivity, epsilon)\n",
    "print(f\"Original Value: {original_value}\")\n",
    "print(f\"Noisy Value (Differential Privacy): {noisy_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c34f6-18c4-4847-a43b-3dc23284657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Simulated network traffic patterns (categorical data)\n",
    "traffic_pattern_1 = [1, 2, 1, 2, 3, 1]\n",
    "traffic_pattern_2 = [2, 2, 1, 2, 3, 2]\n",
    "\n",
    "# Calculate mutual information between two traffic patterns\n",
    "mi_score = mutual_info_score(traffic_pattern_1, traffic_pattern_2)\n",
    "print(f\"Mutual Information between traffic patterns: {mi_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5f300-cc6e-4fc6-bcb1-2663e34c2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probabilities and anomaly scores\n",
    "probabilities = np.random.dirichlet(np.ones(5), size=1)[0]\n",
    "anomaly_scores = np.random.uniform(0, 1, size=5)\n",
    "\n",
    "# Combine entropy and anomaly score for a composite metric\n",
    "composite_metric = [p * s for p, s in zip(probabilities, anomaly_scores)]\n",
    "print(\"Composite Metric for Threat Detection:\")\n",
    "print(composite_metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da9afa-033e-4b7c-8df0-5a9b1046327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Joint distribution of two events\n",
    "joint_distribution = np.array([\n",
    "    [0.1, 0.2],  # P(X=0, Y=0) and P(X=0, Y=1)\n",
    "    [0.3, 0.4]   # P(X=1, Y=0) and P(X=1, Y=1)\n",
    "])\n",
    "\n",
    "# Calculate joint entropy\n",
    "joint_entropy = -np.sum(joint_distribution * np.log2(joint_distribution[joint_distribution > 0]))\n",
    "print(f\"Joint Entropy: {joint_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa24a40-e49a-4b43-8c92-68670718f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# P(X|Y) = P(X and Y) / P(Y)\n",
    "marginal_y = np.sum(joint_distribution, axis=0)  # Marginal distribution of Y\n",
    "conditional_entropy = -np.sum(\n",
    "    joint_distribution * np.log2(joint_distribution / marginal_y[np.newaxis, :])\n",
    ")\n",
    "\n",
    "print(f\"Conditional Entropy H(X|Y): {conditional_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203adab-3010-44fa-ba82-3192dd56b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated traffic packet counts per second\n",
    "normal_traffic = np.random.randint(40, 60, 100)  # Normal range\n",
    "anomalous_traffic = np.append(normal_traffic, np.random.randint(500, 600, 5))  # Spike anomaly\n",
    "\n",
    "# Sliding window entropy detection\n",
    "def sliding_window_entropy(data, window_size):\n",
    "    entropies = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window = data[i:i + window_size]\n",
    "        values, counts = np.unique(window, return_counts=True)\n",
    "        probabilities = counts / len(window)\n",
    "        entropies.append(-np.sum(probabilities * np.log2(probabilities)))\n",
    "    return entropies\n",
    "\n",
    "window_entropies = sliding_window_entropy(anomalous_traffic, window_size=10)\n",
    "print(f\"Window Entropies: {window_entropies[:5]}...\")  # Display first few entropies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27042604-316a-4ae0-8656-a84a3796a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated key, plaintext, and ciphertext distributions\n",
    "plaintext_distribution = np.array([0.5, 0.5])  # P(P)\n",
    "key_distribution = np.array([0.5, 0.5])  # P(K)\n",
    "ciphertext_distribution = np.array([0.5, 0.5])  # P(C)\n",
    "\n",
    "# Verify perfect secrecy: P(C) == P(P)\n",
    "perfect_secrecy = np.allclose(plaintext_distribution, ciphertext_distribution)\n",
    "print(f\"Is the encryption scheme perfectly secret? {perfect_secrecy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6842c3-c250-48d2-a8aa-be04a03cf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated packed malware data (low entropy binary)\n",
    "packed_binary = np.random.choice([0, 1], size=1024, p=[0.8, 0.2])\n",
    "entropy = calculate_file_entropy(packed_binary.tobytes())\n",
    "\n",
    "# Threshold for detecting packed binaries\n",
    "threshold = 4.0\n",
    "is_packed = entropy < threshold\n",
    "print(f\"Entropy: {entropy:.4f}\")\n",
    "print(f\"Is the binary packed malware? {is_packed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489c1b2-e0f0-4786-a17b-5997c6dc5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated IP addresses (categorical data)\n",
    "ip_addresses = [\"192.168.1.1\", \"192.168.1.2\", \"10.0.0.1\", \"192.168.1.1\", \"10.0.0.1\"]\n",
    "actions = [\"LOGIN\", \"LOGOUT\", \"UPLOAD\", \"LOGIN\", \"UPLOAD\"]\n",
    "\n",
    "# Calculate conditional entropy H(Actions|IP)\n",
    "joint_probs = {}\n",
    "for ip, action in zip(ip_addresses, actions):\n",
    "    joint_probs[(ip, action)] = joint_probs.get((ip, action), 0) + 1\n",
    "joint_probs = {k: v / len(actions) for k, v in joint_probs.items()}\n",
    "\n",
    "# Marginal probabilities of IP\n",
    "marginal_probs = {}\n",
    "for ip in ip_addresses:\n",
    "    marginal_probs[ip] = marginal_probs.get(ip, 0) + 1\n",
    "marginal_probs = {k: v / len(ip_addresses) for k, v in marginal_probs.items()}\n",
    "\n",
    "conditional_entropy = 0\n",
    "for (ip, action), p_joint in joint_probs.items():\n",
    "    conditional_entropy -= p_joint * np.log2(p_joint / marginal_probs[ip])\n",
    "\n",
    "print(f\"Conditional Entropy H(Actions|IP): {conditional_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b080a4f-f18b-4eae-8d00-969b1febcfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated probabilities for different threat levels\n",
    "threat_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "threat_probabilities = [0.6, 0.3, 0.1]\n",
    "\n",
    "# Calculate entropy\n",
    "entropy = -np.sum([p * np.log2(p) for p in threat_probabilities])\n",
    "\n",
    "# Bar chart of threat probabilities\n",
    "plt.bar(threat_levels, threat_probabilities, color='blue')\n",
    "plt.title(f\"Threat Levels (Entropy: {entropy:.4f} bits)\")\n",
    "plt.xlabel(\"Threat Level\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640daabb-7588-4a99-8e19-f48b68ab6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Simulated model and data\n",
    "model = lambda x: x.sum(dim=1)  # Simple sum model\n",
    "data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Adversarial noise generation\n",
    "epsilon = 0.1\n",
    "noise = epsilon * torch.randn_like(data)\n",
    "adversarial_data = data + noise\n",
    "\n",
    "# Outputs before and after attack\n",
    "original_output = model(data)\n",
    "adversarial_output = model(adversarial_data)\n",
    "\n",
    "print(f\"Original Output: {original_output}\")\n",
    "print(f\"Adversarial Output: {adversarial_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcada776-3f20-4ff7-946a-2dddda5a2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate network traffic\n",
    "traffic = np.random.randint(1, 100, size=200)\n",
    "\n",
    "# Calculate entropy over time\n",
    "entropies = sliding_window_entropy(traffic, window_size=20)\n",
    "\n",
    "# Visualize\n",
    "plt.plot(entropies)\n",
    "plt.title(\"Traffic Entropy Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65035f5f-62f4-447e-bd75-b42af75431c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f893675-8abc-4fab-88b8-1dfe03527afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5bbc9-4d75-49ac-92d6-d5f0a97e2402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a838a-b3b9-4670-98fb-8de4076d7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e741a-e96c-48b8-a5e3-f4edc47258b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185c191-c731-46cf-93c4-3af258d8c600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8e91b-246e-47db-b87a-95fec7055c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353d932-d3a0-409a-b6f3-60767cfa6135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd2491-0f59-4b6d-b30f-96c786909492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393fd31-1449-42e1-bf04-ea9dcdd920da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1857fd5-5be4-4c3e-9880-f5baa3a0b277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6be41-f336-4b18-a174-51afde4c39bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
