{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1015a910-1740-45ff-82e7-1a158e19d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "## from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc02659-9a78-4b6e-bd73-f8a49b32a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_open_params(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5050010d-f767-4c09-9aef-5e1534671503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AgPO89RRiwfxjYJk33f8VpoDFYnC7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The sky is a vast expanse that often captivates our imagination. It can be a brilliant blue during the day, adorned with fluffy white clouds, or transformed into a stunning palette of oranges and pinks at sunset. At night, it reveals a tapestry of stars, planets, and sometimes the moon, evoking a sense of wonder about the universe. What aspect of the sky are you interested in exploring?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734670732, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0aa8d3e20b', usage=CompletionUsage(completion_tokens=83, prompt_tokens=10, total_tokens=93, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# basic example\n",
    "params = set_open_params()\n",
    "\n",
    "prompt = \"The sky is\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3386d44c-0f0e-4e16-a6fb-efb1cf012283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's identify the odd numbers in the group: 15, 5, 13, 7, and 1. \n",
       "\n",
       "Now, let's add them together:\n",
       "\n",
       "15 + 5 + 13 + 7 + 1 = 41.\n",
       "\n",
       "Since 41 is an odd number, the statement is False. The odd numbers in this group do not add up to an even number."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37daaeb-6f3d-4dfd-9eb2-e3357798eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1096e0a-398e-401a-bc5a-cf5003567607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad94ff-db25-4510-9cbd-8ca00d782c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90ea02-3a0b-4d54-968d-42b1d42457cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a3639-19ff-4dfe-87ee-5fa74e53917c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7eceb2-edac-433f-b748-e8ddf83f4905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f5d8-8bd3-4daf-aa83-2defa71d3b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648500ca-b5b9-4cf4-b619-f3fcbdd258d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddfd182-7e8c-4241-88df-fc42988bb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Random data distribution (e.g., probabilities of events)\n",
    "data_distribution = [0.2, 0.5, 0.3]\n",
    "\n",
    "# Calculate Shannon entropy\n",
    "shannon_entropy = entropy(data_distribution, base=2)  # Base 2 for bits\n",
    "print(f\"Shannon Entropy: {shannon_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f8e62-3014-4eef-a0a2-98b13575bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulated network traffic data (packet sizes in bytes)\n",
    "network_traffic = [40, 40, 45, 50, 55, 500, 45, 50, 60, 55]  # Anomalous 500\n",
    "\n",
    "# Calculate entropy\n",
    "def calculate_entropy(data):\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    probabilities = counts / len(data)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "entropy_before = calculate_entropy(network_traffic[:-1])  # Normal traffic\n",
    "entropy_after = calculate_entropy(network_traffic)  # With anomaly\n",
    "\n",
    "print(f\"Entropy before anomaly: {entropy_before:.4f}\")\n",
    "print(f\"Entropy after anomaly: {entropy_after:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f39569-a14e-47b8-9c3e-0f6ba1f4fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "# Simulated dataset (features and labels)\n",
    "X = np.array([[1, 0], [0, 1], [1, 1], [0, 0], [1, 0]])  # Features\n",
    "y = np.array([0, 1, 1, 0, 0])  # Labels\n",
    "\n",
    "# Calculate mutual information\n",
    "mi = mutual_info_classif(X, y, discrete_features=True)\n",
    "print(f\"Mutual Information between features and labels: {mi}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997c906-194b-442f-ae90-2100a2ea9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate key distribution (probabilities of each key being used)\n",
    "key_distribution = [0.7, 0.2, 0.1]\n",
    "\n",
    "# Calculate entropy of the key distribution\n",
    "key_entropy = -np.sum([p * np.log2(p) for p in key_distribution])\n",
    "print(f\"Entropy of key distribution: {key_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d38ed-fc57-4fca-9f5a-005a9477e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_file_entropy(file_data):\n",
    "    \"\"\"Calculate Shannon entropy of a binary file.\"\"\"\n",
    "    byte_counts = np.bincount(np.frombuffer(file_data, dtype=np.uint8), minlength=256)\n",
    "    probabilities = byte_counts / len(file_data)\n",
    "    probabilities = probabilities[probabilities > 0]  # Filter non-zero probabilities\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Simulated binary file (random bytes)\n",
    "file_data = np.random.randint(0, 256, size=1024, dtype=np.uint8).tobytes()\n",
    "\n",
    "file_entropy = calculate_file_entropy(file_data)\n",
    "print(f\"File Entropy: {file_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5798a1e-6b4e-46c3-b79c-890f672889fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Simulated network traffic distributions (normal vs. anomaly)\n",
    "normal_traffic = [0.4, 0.3, 0.2, 0.1]\n",
    "anomalous_traffic = [0.1, 0.3, 0.4, 0.2]\n",
    "\n",
    "# Calculate KL divergence\n",
    "kl_divergence = entropy(normal_traffic, anomalous_traffic)\n",
    "print(f\"KL Divergence: {kl_divergence:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7e042-0be9-49ac-a035-ebc226094a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data and calculate entropy over a sliding window\n",
    "data = np.random.randint(1, 100, 100)\n",
    "window_size = 10\n",
    "entropies = [calculate_entropy(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "\n",
    "# Plot entropy over time\n",
    "plt.plot(entropies)\n",
    "plt.title(\"Entropy Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf77b89-49eb-4d35-a26c-a83986513ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated risk probabilities for a set of cyber threats\n",
    "threat_probabilities = [0.1, 0.2, 0.4, 0.3]\n",
    "\n",
    "# Calculate entropy as a measure of uncertainty in threat likelihood\n",
    "risk_entropy = -np.sum([p * np.log2(p) for p in threat_probabilities])\n",
    "print(f\"Risk Entropy: {risk_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9750707-fc7c-4906-ab5b-c1a8e83ccc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated impact scores for cyber threats\n",
    "threat_impacts = [0.8, 0.5, 0.9, 0.6]\n",
    "expected_risks = [p * i for p, i in zip(threat_probabilities, threat_impacts)]\n",
    "\n",
    "# Select the threat with the highest expected risk\n",
    "highest_risk_index = np.argmax(expected_risks)\n",
    "print(f\"Threat with highest expected risk: {highest_risk_index}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e8fc7-1b53-4afa-9849-519416095d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probability distributions of model predictions\n",
    "original_distribution = [0.7, 0.2, 0.1]\n",
    "adversarial_distribution = [0.4, 0.4, 0.2]\n",
    "\n",
    "# KL Divergence to measure the effect of the adversarial attack\n",
    "kl_div = entropy(original_distribution, adversarial_distribution)\n",
    "print(f\"KL Divergence between original and adversarial: {kl_div:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a2a8a-f6a3-48ed-acc5-27fb3443c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quantum entropy calculation (von Neumann entropy)\n",
    "def quantum_entropy(density_matrix):\n",
    "    \"\"\"Calculate von Neumann entropy from a density matrix.\"\"\"\n",
    "    eigenvalues = np.linalg.eigvals(density_matrix)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]  # Filter out zero eigenvalues\n",
    "    return -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "\n",
    "# Example density matrix (random Hermitian positive-definite matrix)\n",
    "density_matrix = np.array([[0.5, 0.1], [0.1, 0.5]])\n",
    "quantum_entropy_value = quantum_entropy(density_matrix)\n",
    "print(f\"Quantum Entropy: {quantum_entropy_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a7766-e145-4a96-ac3d-3be37f721115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated attack probabilities and entropy changes\n",
    "attack_probabilities = [0.2, 0.5, 0.3]  # Before detection system\n",
    "updated_probabilities = [0.1, 0.7, 0.2]  # After detection system\n",
    "\n",
    "# Calculate information gained by the system\n",
    "initial_entropy = entropy(attack_probabilities, base=2)\n",
    "updated_entropy = entropy(updated_probabilities, base=2)\n",
    "information_gain = initial_entropy - updated_entropy\n",
    "\n",
    "print(f\"Initial Entropy: {initial_entropy:.4f} bits\")\n",
    "print(f\"Updated Entropy: {updated_entropy:.4f} bits\")\n",
    "print(f\"Information Gain: {information_gain:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4e301-ca34-4b5b-a3c1-d3a5c63bade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probabilities of data exposure in different scenarios\n",
    "exposure_probabilities = [0.6, 0.3, 0.1]\n",
    "\n",
    "# Calculate entropy to quantify uncertainty about data exposure\n",
    "exposure_entropy = -np.sum([p * np.log2(p) for p in exposure_probabilities])\n",
    "print(f\"Data Exposure Entropy: {exposure_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ece91-9f81-429c-9470-f1b26cf2e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Adding Laplace noise for differential privacy\n",
    "def add_laplace_noise(value, sensitivity, epsilon):\n",
    "    \"\"\"Add Laplace noise to a value for differential privacy.\"\"\"\n",
    "    noise = np.random.laplace(0, sensitivity / epsilon)\n",
    "    return value + noise\n",
    "\n",
    "# Original value and sensitivity\n",
    "original_value = 100  # e.g., a count of events\n",
    "sensitivity = 1\n",
    "epsilon = 0.5\n",
    "\n",
    "noisy_value = add_laplace_noise(original_value, sensitivity, epsilon)\n",
    "print(f\"Original Value: {original_value}\")\n",
    "print(f\"Noisy Value (Differential Privacy): {noisy_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c34f6-18c4-4847-a43b-3dc23284657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Simulated network traffic patterns (categorical data)\n",
    "traffic_pattern_1 = [1, 2, 1, 2, 3, 1]\n",
    "traffic_pattern_2 = [2, 2, 1, 2, 3, 2]\n",
    "\n",
    "# Calculate mutual information between two traffic patterns\n",
    "mi_score = mutual_info_score(traffic_pattern_1, traffic_pattern_2)\n",
    "print(f\"Mutual Information between traffic patterns: {mi_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5f300-cc6e-4fc6-bcb1-2663e34c2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated probabilities and anomaly scores\n",
    "probabilities = np.random.dirichlet(np.ones(5), size=1)[0]\n",
    "anomaly_scores = np.random.uniform(0, 1, size=5)\n",
    "\n",
    "# Combine entropy and anomaly score for a composite metric\n",
    "composite_metric = [p * s for p, s in zip(probabilities, anomaly_scores)]\n",
    "print(\"Composite Metric for Threat Detection:\")\n",
    "print(composite_metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da9afa-033e-4b7c-8df0-5a9b1046327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Joint distribution of two events\n",
    "joint_distribution = np.array([\n",
    "    [0.1, 0.2],  # P(X=0, Y=0) and P(X=0, Y=1)\n",
    "    [0.3, 0.4]   # P(X=1, Y=0) and P(X=1, Y=1)\n",
    "])\n",
    "\n",
    "# Calculate joint entropy\n",
    "joint_entropy = -np.sum(joint_distribution * np.log2(joint_distribution[joint_distribution > 0]))\n",
    "print(f\"Joint Entropy: {joint_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa24a40-e49a-4b43-8c92-68670718f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# P(X|Y) = P(X and Y) / P(Y)\n",
    "marginal_y = np.sum(joint_distribution, axis=0)  # Marginal distribution of Y\n",
    "conditional_entropy = -np.sum(\n",
    "    joint_distribution * np.log2(joint_distribution / marginal_y[np.newaxis, :])\n",
    ")\n",
    "\n",
    "print(f\"Conditional Entropy H(X|Y): {conditional_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203adab-3010-44fa-ba82-3192dd56b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated traffic packet counts per second\n",
    "normal_traffic = np.random.randint(40, 60, 100)  # Normal range\n",
    "anomalous_traffic = np.append(normal_traffic, np.random.randint(500, 600, 5))  # Spike anomaly\n",
    "\n",
    "# Sliding window entropy detection\n",
    "def sliding_window_entropy(data, window_size):\n",
    "    entropies = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window = data[i:i + window_size]\n",
    "        values, counts = np.unique(window, return_counts=True)\n",
    "        probabilities = counts / len(window)\n",
    "        entropies.append(-np.sum(probabilities * np.log2(probabilities)))\n",
    "    return entropies\n",
    "\n",
    "window_entropies = sliding_window_entropy(anomalous_traffic, window_size=10)\n",
    "print(f\"Window Entropies: {window_entropies[:5]}...\")  # Display first few entropies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27042604-316a-4ae0-8656-a84a3796a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated key, plaintext, and ciphertext distributions\n",
    "plaintext_distribution = np.array([0.5, 0.5])  # P(P)\n",
    "key_distribution = np.array([0.5, 0.5])  # P(K)\n",
    "ciphertext_distribution = np.array([0.5, 0.5])  # P(C)\n",
    "\n",
    "# Verify perfect secrecy: P(C) == P(P)\n",
    "perfect_secrecy = np.allclose(plaintext_distribution, ciphertext_distribution)\n",
    "print(f\"Is the encryption scheme perfectly secret? {perfect_secrecy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6842c3-c250-48d2-a8aa-be04a03cf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated packed malware data (low entropy binary)\n",
    "packed_binary = np.random.choice([0, 1], size=1024, p=[0.8, 0.2])\n",
    "entropy = calculate_file_entropy(packed_binary.tobytes())\n",
    "\n",
    "# Threshold for detecting packed binaries\n",
    "threshold = 4.0\n",
    "is_packed = entropy < threshold\n",
    "print(f\"Entropy: {entropy:.4f}\")\n",
    "print(f\"Is the binary packed malware? {is_packed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489c1b2-e0f0-4786-a17b-5997c6dc5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulated IP addresses (categorical data)\n",
    "ip_addresses = [\"192.168.1.1\", \"192.168.1.2\", \"10.0.0.1\", \"192.168.1.1\", \"10.0.0.1\"]\n",
    "actions = [\"LOGIN\", \"LOGOUT\", \"UPLOAD\", \"LOGIN\", \"UPLOAD\"]\n",
    "\n",
    "# Calculate conditional entropy H(Actions|IP)\n",
    "joint_probs = {}\n",
    "for ip, action in zip(ip_addresses, actions):\n",
    "    joint_probs[(ip, action)] = joint_probs.get((ip, action), 0) + 1\n",
    "joint_probs = {k: v / len(actions) for k, v in joint_probs.items()}\n",
    "\n",
    "# Marginal probabilities of IP\n",
    "marginal_probs = {}\n",
    "for ip in ip_addresses:\n",
    "    marginal_probs[ip] = marginal_probs.get(ip, 0) + 1\n",
    "marginal_probs = {k: v / len(ip_addresses) for k, v in marginal_probs.items()}\n",
    "\n",
    "conditional_entropy = 0\n",
    "for (ip, action), p_joint in joint_probs.items():\n",
    "    conditional_entropy -= p_joint * np.log2(p_joint / marginal_probs[ip])\n",
    "\n",
    "print(f\"Conditional Entropy H(Actions|IP): {conditional_entropy:.4f} bits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b080a4f-f18b-4eae-8d00-969b1febcfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated probabilities for different threat levels\n",
    "threat_levels = [\"Low\", \"Medium\", \"High\"]\n",
    "threat_probabilities = [0.6, 0.3, 0.1]\n",
    "\n",
    "# Calculate entropy\n",
    "entropy = -np.sum([p * np.log2(p) for p in threat_probabilities])\n",
    "\n",
    "# Bar chart of threat probabilities\n",
    "plt.bar(threat_levels, threat_probabilities, color='blue')\n",
    "plt.title(f\"Threat Levels (Entropy: {entropy:.4f} bits)\")\n",
    "plt.xlabel(\"Threat Level\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640daabb-7588-4a99-8e19-f48b68ab6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Simulated model and data\n",
    "model = lambda x: x.sum(dim=1)  # Simple sum model\n",
    "data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Adversarial noise generation\n",
    "epsilon = 0.1\n",
    "noise = epsilon * torch.randn_like(data)\n",
    "adversarial_data = data + noise\n",
    "\n",
    "# Outputs before and after attack\n",
    "original_output = model(data)\n",
    "adversarial_output = model(adversarial_data)\n",
    "\n",
    "print(f\"Original Output: {original_output}\")\n",
    "print(f\"Adversarial Output: {adversarial_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcada776-3f20-4ff7-946a-2dddda5a2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate network traffic\n",
    "traffic = np.random.randint(1, 100, size=200)\n",
    "\n",
    "# Calculate entropy over time\n",
    "entropies = sliding_window_entropy(traffic, window_size=20)\n",
    "\n",
    "# Visualize\n",
    "plt.plot(entropies)\n",
    "plt.title(\"Traffic Entropy Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65035f5f-62f4-447e-bd75-b42af75431c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f893675-8abc-4fab-88b8-1dfe03527afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601c9b2-0953-4006-8d39-2a3cd9439e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load a pre-trained sentiment analysis model and tokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Sentiment Analysis Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define the original input text\n",
    "original_text = \"I love this product. It's fantastic!\"\n",
    "\n",
    "# Function to generate adversarial examples\n",
    "def generate_adversarial_text(text, model, tokenizer, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Generates adversarial text by perturbing token embeddings.\n",
    "\n",
    "    Args:\n",
    "        text (str): Original input text.\n",
    "        model: Hugging Face model.\n",
    "        tokenizer: Hugging Face tokenizer.\n",
    "        epsilon (float): Magnitude of perturbation.\n",
    "\n",
    "    Returns:\n",
    "        str: Adversarial text.\n",
    "    \"\"\"\n",
    "    # Tokenize input and convert to tensors\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    # Get embeddings\n",
    "    embedding_layer = model.get_input_embeddings()\n",
    "    original_embeddings = embedding_layer(input_ids)\n",
    "\n",
    "    # Create adversarial perturbation\n",
    "    perturbation = epsilon * torch.randn_like(original_embeddings)\n",
    "    adversarial_embeddings = original_embeddings + perturbation\n",
    "\n",
    "    # Replace model's embedding layer temporarily with adversarial embeddings\n",
    "    def forward_hook(module, input, output):\n",
    "        return adversarial_embeddings\n",
    "\n",
    "    hook = embedding_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    try:\n",
    "        # Get predictions with adversarial input\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        \n",
    "        # Decode adversarial input back to text (for interpretability)\n",
    "        adversarial_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        adversarial_text = tokenizer.decode(input_ids[0])\n",
    "    finally:\n",
    "        # Remove hook after inference\n",
    "        hook.remove()\n",
    "\n",
    "    return adversarial_text, predicted_class\n",
    "\n",
    "# Generate adversarial example\n",
    "adversarial_text, adversarial_class = generate_adversarial_text(original_text, model, tokenizer)\n",
    "\n",
    "# Print results\n",
    "print(\"Original Text:\", original_text)\n",
    "print(\"Adversarial Text:\", adversarial_text)\n",
    "print(\"Adversarial Class:\", \"Positive\" if adversarial_class == 1 else \"Negative\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70790379-7d07-40ea-99f4-f96e59916fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c187b8-93bd-48ac-940a-da58f3619284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1. Introduction\n",
    "Sections: 1.1. Importance of Cybersecurity in the Modern Era\n",
    "1.2. Overview of Information Theory\n",
    "1.3. Role of Information Theory Metrics in Cybersecurity\n",
    "1.4. Scope and Objectives of the Book\n",
    "2. Fundamentals of Information Theory\n",
    "Sections: 2.1. Key Concepts in Information Theory\n",
    "- Entropy, Joint Entropy, Conditional Entropy\n",
    "- Mutual Information\n",
    "- KL Divergence\n",
    "2.2. Channel Capacity and Noise\n",
    "2.3. Information Compression and Encoding Basics\n",
    "2.4. Applications of Information Theory in Real-World Problems\n",
    "3. Cybersecurity Challenges and Information-Theoretic Perspectives\n",
    "Sections: 3.1. Key Challenges in Cybersecurity\n",
    "- Malware Detection\n",
    "- Network Intrusion Detection\n",
    "- Data Privacy and Leakage\n",
    "- Cryptographic Security\n",
    "3.2. Mapping Cybersecurity Problems to Information Theory Concepts\n",
    "3.3. Advantages of Using Information Theory Metrics\n",
    "4. Metrics for Intrusion Detection\n",
    "Sections: 4.1. Entropy-Based Metrics for Anomaly Detection\n",
    "4.2. Mutual Information for Identifying Suspicious Network Activities\n",
    "4.3. KL Divergence for Statistical Anomaly Detection\n",
    "4.4. Use Cases:\n",
    "- Detecting Denial-of-Service (DoS) Attacks\n",
    "- Monitoring Traffic for Botnets\n",
    "5. Metrics for Data Privacy and Leakage Prevention\n",
    "Sections: 5.1. Quantifying Data Sensitivity with Entropy\n",
    "5.2. Shannon’s Theory and Data Leakage Estimation\n",
    "5.3. Mutual Information for Privacy Preservation\n",
    "5.4. Case Studies:\n",
    "- Differential Privacy\n",
    "- Information Flow Control in Systems\n",
    "6. Cryptography and Information Theory\n",
    "Sections: 6.1. Shannon’s Perfect Secrecy\n",
    "6.2. Information-Theoretic Security vs. Computational Security\n",
    "6.3. Key Distribution and Capacity\n",
    "6.4. Evaluating Cryptographic Protocols Using Entropy and Mutual Information\n",
    "7. Metrics for Malware and Ransomware Analysis\n",
    "Sections: 7.1. Entropy Analysis of Binary Files\n",
    "7.2. Mutual Information for Behavior Analysis\n",
    "7.3. Case Studies:\n",
    "- Identifying Packed Malware\n",
    "- Analyzing Ransomware Payloads\n",
    "8. Network Security and Information Theory\n",
    "Sections: 8.1. Measuring Network Uncertainty with Entropy\n",
    "8.2. Mutual Information for Traffic Correlation and Forensics\n",
    "8.3. Using KL Divergence for Protocol Anomaly Detection\n",
    "8.4. Practical Applications:\n",
    "- Securing IoT Networks\n",
    "- Detecting Advanced Persistent Threats (APTs)\n",
    "9. Information Theory for Risk Assessment\n",
    "Sections: 9.1. Quantifying Risk Using Entropy\n",
    "9.2. Mutual Information for Understanding Attack Impact\n",
    "9.3. Decision-Making Frameworks Based on Information Metrics\n",
    "9.4. Examples in Enterprise Security\n",
    "10. Advanced Topics and Emerging Trends\n",
    "Sections: 10.1. Information-Theoretic Metrics for AI-Based Cybersecurity\n",
    "10.2. Adversarial Attacks and Information Theory\n",
    "10.3. Quantum Information Theory in Cybersecurity\n",
    "10.4. Future Directions for Research\n",
    "11. Practical Implementations and Tools\n",
    "Sections: 11.1. Open-Source Libraries for Information Theory Applications\n",
    "11.2. Building Metrics with Python\n",
    "11.3. Case Study: End-to-End Example of Using Information Theory in Cybersecurity\n",
    "11.4. Challenges and Limitations of Practical Implementations\n",
    "12. Conclusion and Future Outlook\n",
    "Sections: 12.1. Recap of Key Concepts and Metrics\n",
    "12.2. The Evolving Role of Information Theory in Cybersecurity\n",
    "12.3. Recommendations for Researchers and Practitioners\n",
    "12.4. Final Thoughts\n",
    "Appendices\n",
    "A. Mathematical Foundations of Information Theory\n",
    "B. Glossary of Terms\n",
    "C. References and Further Reading\n",
    "D. Code Snippets and Practical Guides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e832c3-9ae6-49f0-ae6c-8e6a120d52d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5bbc9-4d75-49ac-92d6-d5f0a97e2402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a838a-b3b9-4670-98fb-8de4076d7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e741a-e96c-48b8-a5e3-f4edc47258b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185c191-c731-46cf-93c4-3af258d8c600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8e91b-246e-47db-b87a-95fec7055c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353d932-d3a0-409a-b6f3-60767cfa6135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd2491-0f59-4b6d-b30f-96c786909492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393fd31-1449-42e1-bf04-ea9dcdd920da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1857fd5-5be4-4c3e-9880-f5baa3a0b277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6be41-f336-4b18-a174-51afde4c39bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
