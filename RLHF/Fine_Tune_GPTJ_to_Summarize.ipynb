{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b3a39d",
   "metadata": {},
   "source": [
    "\n",
    "## Fine Tune GPTJ to Summarize\n",
    "\n",
    "* Ref: OpenAI, CarperAI, HF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4956eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install evaluate\n",
    "## !pip install rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16658b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import random\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f203cca",
   "metadata": {},
   "source": [
    "\n",
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b29b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set up the metric\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919951f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir                  = \"gptj-supervised-summarize-checkpoint\"\n",
    "train_batch_size            = 16\n",
    "gradient_accumulation_steps = 1\n",
    "learning_rate               = 1e-5\n",
    "eval_batch_size             = 1\n",
    "eval_steps                  = 500\n",
    "max_input_length            = 550\n",
    "save_steps                  = 1000\n",
    "num_train_epochs            = 1         ## 5\n",
    "\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850a81f",
   "metadata": {},
   "source": [
    "\n",
    "## Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99096981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset_from_jsonl(jsonl_file, return_summary=True):\n",
    "    # if return_summary is True, return a list of posts with summary concatenated\n",
    "    # if return_summary is False, return a list of posts and a list of summaries\n",
    "    with open(jsonl_file, \"r\") as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "    post_list = []\n",
    "    summary_list = []\n",
    "    for d in dataset:\n",
    "        if return_summary:\n",
    "            post = f\"SUBREDDIT: r/{d['subreddit']}\\nTITLE: {d['title']}\\nPOST: {d['post']}\\nTL;DR: {d['summary']}\"\n",
    "        else:\n",
    "            post = f\"SUBREDDIT: r/{d['subreddit']}\\nTITLE: {d['title']}\\nPOST: {d['post']}\\nTL;DR: \"\n",
    "            summary_list.append(d[\"summary\"])\n",
    "        post_list.append(post)\n",
    "    if not return_summary:\n",
    "        return post_list, summary_list\n",
    "    return post_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfe7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68649445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels_ids = eval_preds.label_ids\n",
    "    pred_ids   = eval_preds.predictions\n",
    "    pred_str   = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str  = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    result     = rouge.compute(predictions=pred_str, references=label_str)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0dfe2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a preprocessing function to extract out the proper logits from the model output\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3fec6",
   "metadata": {},
   "source": [
    "\n",
    "## Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdbce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TLDRDataset(Dataset):\n",
    "    def __init__(self, train_path, tokenizer, split, max_length=550):\n",
    "        self.post_list = []\n",
    "        dataset = load_dataset(train_path, split=split)\n",
    "        for sample in dataset:\n",
    "            self.post_list.append(sample[\"prompt\"] + sample[\"label\"])\n",
    "        if \"valid\" in split:\n",
    "            self.post_list = self.post_list[0:2000]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.post_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.post_list[idx]\n",
    "        encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
    "        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
    "        attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attn_masks,\n",
    "            \"labels\": input_ids,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ComparisonDataset(Dataset):\n",
    "    def __init__(self, comparison_path, tokenizer, max_length=550):\n",
    "        with open(comparison_path, \"r\") as f:\n",
    "            dataset = [json.loads(line) for line in f]\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.post_list = []\n",
    "        self.summaries_0 = []\n",
    "        self.summaries_1 = []\n",
    "        self.labels = []\n",
    "        self.max_length = max_length\n",
    "\n",
    "        def make_text(post, summarize):\n",
    "            return f\"SUBREDDIT: r/{post['subreddit']}\\nTITLE: {post['title']}\\nPOST: {post['post']}\\nTL;DR: {summarize}\"\n",
    "\n",
    "        for sample in dataset:  # chosen summary is always the first one\n",
    "            self.post_list.append(sample[\"info\"][\"post\"])\n",
    "            # NOTE: The chosen summary is always the first one, i.e. `sample[\"summaries\"][0]`\n",
    "            if sample[\"choice\"] == 0:\n",
    "                self.summaries_0.append(make_text(sample[\"info\"], sample[\"summaries\"][0][\"text\"]))\n",
    "                self.summaries_1.append(make_text(sample[\"info\"], sample[\"summaries\"][1][\"text\"]))\n",
    "            else:\n",
    "                self.summaries_0.append(make_text(sample[\"info\"], sample[\"summaries\"][1][\"text\"]))\n",
    "                self.summaries_1.append(make_text(sample[\"info\"], sample[\"summaries\"][0][\"text\"]))\n",
    "            self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.post_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        summ0 = self.summaries_0[idx]\n",
    "        summ1 = self.summaries_1[idx]\n",
    "        encodings_dict = self.tokenizer(\n",
    "            [summ0, summ1],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
    "        attention_mask = torch.tensor(encodings_dict[\"attention_mask\"])\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a0840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AllSummDataset(Dataset):\n",
    "    def __init__(self, train_path, tokenizer, split, max_length=1024):\n",
    "        df = pd.read_parquet(train_path)\n",
    "        if split == \"valid\":\n",
    "            df = df.sample(n=5000)\n",
    "        self.summarizes = []\n",
    "        for i, row in df.iterrows():\n",
    "            self.summarizes.append(f\"Summarize: {row['text']}. TL;DR: {row['summary']}\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.summarizes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.summarizes[idx]\n",
    "        encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
    "        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
    "        attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attn_masks,\n",
    "            \"labels\": input_ids,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d523d",
   "metadata": {},
   "source": [
    "\n",
    "## Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ba8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer              = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "tokenizer.pad_token    = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b973927",
   "metadata": {},
   "source": [
    "\n",
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbcdeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9617669f9f3497f97c91ae4d7bacee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95efd5b1a5341019814afb5648ef4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", use_cache=False)\n",
    "\n",
    "model.resize_token_embeddings( len(tokenizer) )\n",
    "\n",
    "model.config.end_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e15742",
   "metadata": {},
   "source": [
    "\n",
    "## Set up the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"CarperAI/openai_summarize_tldr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e494ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "train_dataset = TLDRDataset(\n",
    "    data_path,\n",
    "    tokenizer,\n",
    "    \"train\",\n",
    "    max_length=max_input_length,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dev_dataset = TLDRDataset(\n",
    "    data_path,\n",
    "    tokenizer,\n",
    "    \"valid\",\n",
    "    max_length=max_input_length,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20815c",
   "metadata": {},
   "source": [
    "\n",
    "## Prepare the trainer and start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2de752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = output_dir,\n",
    "    evaluation_strategy         = \"steps\",\n",
    "    eval_accumulation_steps     = 1,\n",
    "    learning_rate               = learning_rate,\n",
    "    per_device_train_batch_size = train_batch_size,\n",
    "    per_device_eval_batch_size  = eval_batch_size,\n",
    "    gradient_checkpointing      = True,\n",
    "    half_precision_backend      = True,\n",
    "    fp16                        = True,\n",
    "    adam_beta1                  = 0.9,\n",
    "    adam_beta2                  = 0.95,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    num_train_epochs            = num_train_epochs,\n",
    "    warmup_steps                = 1,\n",
    "    eval_steps                  = eval_steps,\n",
    "    save_steps                  = save_steps,\n",
    "    load_best_model_at_end      = True,\n",
    "    logging_steps               = 50,\n",
    "    deepspeed                   = \"./ds_config_gptj.json\",\n",
    "    ## no_cuda                       = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed967c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "trainer = Trainer(\n",
    "    model                         = model,\n",
    "    args                          = training_args,\n",
    "    train_dataset                 = train_dataset,\n",
    "    eval_dataset                  = dev_dataset,\n",
    "    compute_metrics               = compute_metrics,\n",
    "    data_collator                 = default_data_collator,\n",
    "    preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ab01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.save_model(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c07b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f44cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6bf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20acfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f96a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebbd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258b759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a3352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209adf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2c733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681e054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
