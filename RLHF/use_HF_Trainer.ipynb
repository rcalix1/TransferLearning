{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d710d80b",
   "metadata": {},
   "source": [
    "\n",
    "## Example using HF trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForCausalLM, IntervalStrategy, AutoModel, AutoConfig, PreTrainedModel\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model, PreTrainedModel\n",
    "from transformers import AutoModelForCausalLM, GPT2PreTrainedModel, GPT2Model\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch import nn\n",
    "from torch.nn import Identity\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import json\n",
    "import deepspeed\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint = \"roneneldan/TinyStories-33M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ad800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = load_dataset('MohamedRashad/characters_backstories')[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132da41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d26830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_function(example):\n",
    "    merged = example[\"text\"] + \" \" + example[\"target\"]\n",
    "    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ae4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized_dataset = ds.map(tokenize_function, remove_columns=[\"text\", \"target\"])\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\".\",\n",
    "    no_cuda=True\n",
    "    # use_mps_device=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42570740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3328914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(trainer.accelerator.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's train!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3326a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab92c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be9834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a045f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e104b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd2f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
