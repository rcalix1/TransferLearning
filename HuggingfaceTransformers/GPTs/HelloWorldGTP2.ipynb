{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a8b79e",
   "metadata": {},
   "source": [
    "\n",
    "## Hello World. I am GPT2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6a2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f8be505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a4d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed                   = 42\n",
    "max_length             = 150\n",
    "num_return_sequences   = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b60be09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_examples( generator, prompt_list ):\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    for prompt in prompt_list:\n",
    "        \n",
    "        result = generator(\n",
    "                   prompt, \n",
    "                   max_length           = max_length, \n",
    "                   num_return_sequences = num_return_sequences\n",
    "        )\n",
    "        \n",
    "        example = {'prompt': prompt}\n",
    "        \n",
    "        for i, res in enumerate( result ):\n",
    "            \n",
    "            ## answer = res['generated_text'].lstrip().removeprefix( prompt ).strip()\n",
    "            answer    = res['generated_text'].lstrip().strip()\n",
    "            \n",
    "            example[f'answer{ i + 1 }'] = answer\n",
    "            \n",
    "        examples.append(example)\n",
    "        \n",
    "        ## print(examples)\n",
    "        print( json.dumps( example, indent = 2) )\n",
    "        \n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a6d46",
   "metadata": {},
   "source": [
    "\n",
    "## Get GPT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f671e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name           = 'gpt2'\n",
    "\n",
    "model_gpt_generator  = pipeline('text-generation', model=model_name )   ## , device=0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd90ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer              = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "##  tokenizer.pad_token    = tokenizer.eos_token\n",
    "## tokenizer.padding_side = \"left\"\n",
    "\n",
    "## max_length_input = train_seq_length - method_max_new_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22c9a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"When will it snow this week?\",\n",
      "  \"answer1\": \"When will it snow this week? Last weekend, in the northern part of the state it was overcast. In November, above 100 degrees. Even then, summer can be quite harsh.\\n\\nWon't snow in all areas this year? Stay tuned. Because snowstorms last months on June 26 and July 26, 2016.\\n\\nAs of 4:40 pm on August 12, 2012, the highest snowfall on the day of the storm was 4 feet (2.2 meters) in Longmont near the Montrose intersection. On this morning, the snow was nearly 4 feet (12 meters) above average.\\n\\nDid you know that the high winds on last summer's High Pressure Storm were blowing so fast that it felt like\",\n",
      "  \"answer2\": \"When will it snow this week? What was your favorite sport, and then how would you like to play it next Sunday? Email bryan@dailykos.com or follow him on Twitter @Bryan_Karen17.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_to_answer = [\"When will it snow this week?\"]\n",
    "\n",
    "say_something = generate_examples( model_gpt_generator, list_to_answer )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc0f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7991b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6731a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93853a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68b570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb5be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105ee66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
