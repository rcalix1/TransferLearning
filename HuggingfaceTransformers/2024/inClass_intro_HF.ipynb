{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8ec04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install SentencePiece\n",
    "## !pip install torch\n",
    "## !pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0940d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a8d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "model     = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bc37aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 1.0939,  0.5053,  0.1715,  ..., -0.4915, -0.7119,  1.1999],\n",
      "         [ 0.1346,  1.4558,  1.0297,  ..., -0.2366,  1.0784, -0.2260],\n",
      "         [-0.7314, -0.7786, -0.3179,  ...,  0.1351,  1.5941, -0.9347],\n",
      "         ...,\n",
      "         [-0.3901, -0.3225,  0.5177,  ...,  0.1546,  1.4358,  0.5165],\n",
      "         [ 0.6785,  0.1826,  0.2188,  ..., -0.4804,  1.1837,  0.4180],\n",
      "         [ 0.0544,  0.1334, -0.0490,  ..., -0.1220,  0.1077,  0.1971]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5389, -0.6086,  0.8374, -0.8752, -0.6615, -0.9479,  0.5728, -0.5487,\n",
      "          0.5840, -0.9994,  0.8545,  0.5818, -0.5577, -0.9433, -0.9580, -0.5357,\n",
      "          0.6166,  0.5180,  0.9972, -0.5242, -0.7181, -0.9925,  0.9959,  0.9557,\n",
      "          0.5715, -0.5299,  0.6058, -0.9689, -0.9995, -0.5381, -1.0000,  0.6917,\n",
      "          0.5956,  0.5521,  0.5793, -0.4755,  0.6820,  0.9975, -0.6022,  0.6362,\n",
      "          0.5400, -0.9743, -0.7325,  0.6179,  0.5656,  0.5581,  0.9794, -0.9897,\n",
      "          0.8847, -0.5357, -0.5040, -0.4795, -0.5231, -0.9948, -0.4365,  0.6682,\n",
      "         -0.6268, -0.5502,  0.9999, -0.9274,  0.5563, -0.7180,  0.6925, -0.0518,\n",
      "         -0.5860,  0.5159,  0.5491,  0.9987, -0.4818,  0.9509,  0.5379,  0.6610,\n",
      "          0.3893, -0.7199,  0.9678,  0.6112,  0.2541,  0.5337, -0.1678, -0.9875,\n",
      "          0.7976,  0.6921, -0.6272,  0.6089, -0.9083, -0.9670,  0.7986, -0.9999,\n",
      "          0.6013,  0.9556,  0.5744,  0.6996, -0.5221, -1.0000,  0.4949, -0.6163,\n",
      "         -0.9996,  0.6177,  0.4992, -0.6089,  0.0204, -0.4823,  0.6955, -0.6689,\n",
      "         -0.5657, -0.5609,  0.5371,  0.9156,  0.5947,  0.9987, -0.9881, -0.5697,\n",
      "          0.5092,  0.9699, -0.5373,  0.2463, -0.6231,  0.8376, -0.9970,  0.6121,\n",
      "          0.5532, -0.1323,  0.5625, -0.2801,  0.5866, -0.0411,  0.4946, -0.5807,\n",
      "          0.9781, -0.7949,  0.7598,  0.4959, -0.9996, -0.2695,  0.5900,  0.9567,\n",
      "         -0.5043, -0.5384, -0.4652,  0.5677,  0.9913, -0.5343,  0.4876, -0.6243,\n",
      "         -0.5905,  0.5376,  0.1107, -0.4722,  0.5395,  0.9920, -0.9649,  0.9803,\n",
      "          0.6290, -0.9754, -0.9965,  0.4031,  0.9585, -0.8586,  0.7727, -0.6127,\n",
      "         -0.5031, -0.8986, -0.9972, -0.6447, -0.9983, -0.6674,  0.9995, -0.0982,\n",
      "          0.9989, -0.9960, -0.5467,  0.6419, -0.5579,  0.9756,  0.5637,  0.5709,\n",
      "          0.5049,  0.7744, -0.6163, -0.4750,  0.9860, -0.9988,  0.5437,  0.6146,\n",
      "          0.9866,  0.5762,  0.6972, -0.8261,  0.5362, -0.7132, -0.5479, -0.8171,\n",
      "          0.6692,  0.8044,  1.0000, -0.6661,  0.9877, -0.9413,  0.9603, -0.9974,\n",
      "         -0.5681,  0.8138,  0.9554,  0.6140,  0.6060,  0.9017, -0.9037, -0.9976,\n",
      "         -1.0000, -0.5775, -0.9990,  0.9761, -0.9929,  0.5654, -0.9995,  0.9895,\n",
      "          0.9828, -0.5895,  0.9999, -0.5955,  0.7423,  0.5605, -1.0000,  0.9405,\n",
      "          0.4755,  0.5402, -0.0427, -0.5301,  0.9834, -0.9979, -0.9650, -0.1920,\n",
      "          0.6147, -0.9998, -0.7863, -0.5956,  0.6833,  0.6220,  0.6133, -0.9984,\n",
      "          0.9997,  0.5902, -0.4455, -0.5963, -0.4481,  1.0000, -0.6990, -0.9864,\n",
      "         -0.5737,  0.9986,  0.9650,  0.6409,  0.7254, -0.5913,  0.7585, -0.4945,\n",
      "         -0.9905, -0.9907, -0.9885,  0.5429, -0.9832,  0.3368, -0.4427, -0.9990,\n",
      "         -0.5921,  0.8455,  0.9974,  0.9907,  0.5569, -0.7269,  0.5541, -0.5849,\n",
      "          0.9503, -0.3441,  0.9727, -0.5766, -0.9643,  0.6135,  0.6478,  0.5075,\n",
      "         -0.6038, -0.9645,  0.6113, -0.5924,  0.9977, -0.8475,  0.9993, -0.9840,\n",
      "         -0.9997,  0.5611, -0.6752, -0.5998,  0.9976, -0.5602, -0.9991, -0.9998,\n",
      "          0.5379,  0.9600,  0.9109, -0.9273,  0.6442, -0.5728, -0.5806,  0.9976,\n",
      "          0.6053, -0.5299, -0.4652,  0.5691,  0.5444,  0.7444, -0.7575, -0.5889,\n",
      "         -0.6324, -0.9904, -0.6146, -0.1315, -0.5207, -0.7519,  0.9885,  0.9849,\n",
      "         -0.5481, -0.7331,  0.9983, -0.9965,  0.6848, -1.0000,  0.8843, -0.9998,\n",
      "         -0.9986, -0.4946, -0.8764, -0.5258, -0.6298, -0.9630,  0.5616, -0.9943,\n",
      "          0.5348, -0.6639,  0.9751,  0.9655, -0.9999, -0.5451, -0.9690,  0.4979,\n",
      "          0.6217,  0.5347,  0.5720, -0.4130,  0.6365, -0.9977,  0.5660,  0.8981,\n",
      "         -0.6503,  0.8731, -0.5977,  0.5923, -0.9534, -0.6619, -0.5056,  0.9936,\n",
      "          0.9946, -0.8731, -0.5158,  0.5799, -0.8774,  0.9835, -0.9888,  0.9781,\n",
      "         -0.9987, -0.6409, -0.9903,  0.9985,  0.9770, -0.0145, -0.6365, -0.8916,\n",
      "         -0.9632,  0.6548, -0.5847, -0.4420, -0.5395,  0.9907,  0.5294,  0.9598,\n",
      "         -0.8369,  0.3878,  0.4403,  0.8903, -0.9897,  0.9904, -0.9379, -0.5925,\n",
      "          0.7264,  1.0000, -0.6151,  0.5495, -0.9939, -0.9947, -0.6024,  0.5712,\n",
      "          0.9903, -0.5553, -0.8521,  0.9633,  0.9941, -0.9958,  0.6838,  0.9977,\n",
      "          0.9777,  0.6092,  0.6768,  0.9565,  0.8763,  0.5598,  0.9858, -0.5119,\n",
      "          0.9999, -0.9974, -0.9997,  0.9946, -0.5673,  0.9900, -0.3811,  0.5111,\n",
      "         -0.5730,  0.6244, -0.6128, -0.5874,  0.5110,  0.7326,  0.6362,  0.9932,\n",
      "          0.4849, -0.9857, -1.0000, -0.4840,  0.7177,  0.7035, -0.5624,  0.9677,\n",
      "         -0.5916,  0.3152, -0.6548, -0.6172,  0.5814, -0.9997,  1.0000, -0.9984,\n",
      "          0.9956, -0.5522,  0.9703,  0.8778,  0.9980, -0.6644, -1.0000, -0.6022,\n",
      "         -0.9981,  0.6386, -0.5405, -0.9466, -0.5577,  0.7479, -0.5130,  0.9974,\n",
      "          0.6783, -0.6663, -0.9988,  1.0000, -0.8558, -0.9997,  0.5939,  0.5842,\n",
      "          0.7857,  0.5055,  0.4649,  0.5300, -0.7545, -0.5991,  0.9925, -0.9735,\n",
      "          0.6699, -0.9737,  0.9788, -0.6243, -0.1971,  0.9100,  0.9976,  0.9965,\n",
      "         -0.5905, -1.0000, -0.9894, -0.9985, -0.9902,  0.5256, -0.9414,  0.8575,\n",
      "         -0.5909, -0.5276,  0.9843,  0.5991, -0.5081, -0.5691, -0.9928, -0.8762,\n",
      "         -0.5308, -0.8378,  0.6305, -0.9992, -0.7223, -0.9795, -0.9966, -0.2209,\n",
      "         -0.9893,  0.5206, -0.9999,  0.1896, -0.5885, -0.2791, -0.5350,  0.6116,\n",
      "          0.5779, -0.5441,  0.5181,  0.9797, -0.6044,  1.0000,  0.9804,  0.9325,\n",
      "          0.6564, -0.5283, -0.5807,  0.9990, -0.5780, -0.3293,  0.8932, -0.9560,\n",
      "          0.2547, -0.9955,  0.9760, -0.7774, -0.9482, -0.9731, -0.6382, -1.0000,\n",
      "         -0.9998, -0.9997,  0.6137,  0.9058, -0.9950,  0.9975,  0.7070, -0.7353,\n",
      "          0.9996,  0.6472, -0.9668,  0.4811, -0.5817,  0.9999, -0.5038,  0.9689,\n",
      "         -0.6226, -0.9957,  0.7648,  0.8525, -0.5277, -0.5593, -0.9321, -0.8895,\n",
      "          0.0924, -0.5239,  0.6398,  1.0000, -0.8751,  0.5711, -0.6633,  0.6174,\n",
      "         -0.9837,  0.5024, -0.3760, -0.0277, -0.9935, -0.9125,  0.9988,  0.5705,\n",
      "          0.6303,  0.5907,  0.6922, -0.4449,  0.9999, -0.9999, -0.4663,  0.5208,\n",
      "         -0.7330,  0.7680, -0.5072, -0.6962,  0.4947,  0.9871, -0.5109,  0.9981,\n",
      "         -0.2512,  0.6404,  0.6248,  0.5514,  0.4868,  0.9998,  0.6474, -0.8779,\n",
      "         -0.5295, -0.5331, -0.5324,  0.9995,  0.9986, -0.9297, -0.8414, -0.4643,\n",
      "         -0.9900,  0.9704,  0.3923,  0.9969,  0.9962,  0.6685, -0.4709, -0.9802,\n",
      "          0.9997,  0.9108, -0.5998,  0.7974,  0.6599, -0.5918,  0.2114,  0.8868,\n",
      "         -0.9023,  0.4456,  0.6417,  0.9894,  0.9965, -0.5891,  0.7945, -1.0000,\n",
      "         -0.5476,  0.9729, -0.9571,  0.6201,  0.9929, -1.0000, -0.5281, -0.5658,\n",
      "          0.9561,  0.9945,  0.4898,  0.5265, -0.4376, -0.6331,  0.9994,  0.5002,\n",
      "         -0.6261,  0.9982, -0.6541, -0.5192,  0.6054,  0.6585,  0.9997,  0.9172,\n",
      "         -0.9721, -0.5747,  0.5340, -0.6338,  0.9969, -0.9998, -0.5476,  0.3739,\n",
      "         -0.9095,  0.4989,  0.7928,  0.6511, -0.6124, -0.9995,  0.5622,  0.9802,\n",
      "          0.6183,  0.9917,  0.5452, -0.3209,  0.6751,  0.8842, -0.0295,  0.8924,\n",
      "         -0.9983,  0.5719, -0.9400,  0.5640, -0.6941, -0.9860, -0.7384,  0.5401,\n",
      "          0.9944,  0.6418,  0.6126,  0.4074, -0.6566,  0.5857,  0.5752,  0.4527,\n",
      "         -0.5325, -0.7019, -0.6813, -0.9992,  0.4352,  0.5594, -0.3176,  0.6317,\n",
      "         -0.5097, -0.9699,  0.5408, -0.5417,  0.6882, -0.5613, -0.9999, -0.6752,\n",
      "         -0.8950, -0.6237,  0.5450, -0.6474,  0.6165, -0.5778, -1.0000, -0.3299,\n",
      "          0.4772, -0.9755,  0.6563, -0.9908,  0.4970,  0.9999,  1.0000, -0.9309,\n",
      "          0.5245, -0.9981, -0.5973, -0.6928, -1.0000,  0.5746,  1.0000,  0.7874,\n",
      "          0.4824, -0.9958, -0.9598,  0.9957, -0.9904, -0.6838,  0.5736, -0.5372,\n",
      "         -0.9996,  0.8443,  0.6096,  0.6239,  0.6185, -0.9927, -0.6150,  0.4123,\n",
      "         -0.9988,  0.5088,  0.9972, -0.5270,  0.5174,  0.2681, -0.9984,  0.6499]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"the cat is so sad .\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ebe7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token     token_str                     sequence\n",
      "0  0.281033  10901          cute          the cat is so cute.\n",
      "1  0.094896  26354      adorable      the cat is so adorable.\n",
      "2  0.042963   1700         happy         the cat is so happy.\n",
      "3  0.040976   5066         funny         the cat is so funny.\n",
      "4  0.024234  28803  affectionate  the cat is so affectionate.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fillmask = pipeline('fill-mask', model='albert-base-v2')\n",
    "\n",
    "res = pd.DataFrame(fillmask(\"The cat is so [MASK] .\"))\n",
    "\n",
    "print(  res   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf469d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token   token_str                          sequence\n",
      "0  0.031417  27668  figurative  el chapo is a figurative person.\n",
      "1  0.028689  18496  franciscan  el chapo is a franciscan person.\n",
      "2  0.025276   9650   dominican   el chapo is a dominican person.\n",
      "3  0.022960  19210    moroccan    el chapo is a moroccan person.\n",
      "4  0.017772  14484      basque      el chapo is a basque person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res1 = pd.DataFrame(fillmask(\"El chapo is a  [MASK] person.\"))\n",
    "print(  res1   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dc8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token  token_str                     sequence\n",
      "0  0.059892   5934  wonderful  anna is a wonderful person.\n",
      "1  0.057768   5066      funny      anna is a funny person.\n",
      "2  0.047015    254       good       anna is a good person.\n",
      "3  0.046512   8601     lovely     anna is a lovely person.\n",
      "4  0.038440   2210       nice       anna is a nice person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "res2 = pd.DataFrame(fillmask(\"Anna is a  [MASK] person.\"))\n",
    "print(  res2   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5552bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token  token_str                        sequence\n",
      "0  0.090353   5934  wonderful  michael is a wonderful person.\n",
      "1  0.056277    254       good       michael is a good person.\n",
      "2  0.054211   5066      funny      michael is a funny person.\n",
      "3  0.051298    374      great      michael is a great person.\n",
      "4  0.049223   2210       nice       michael is a nice person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"Michael is a  [MASK] person.\"))\n",
    "print(  res3   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e28e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token token_str  \\\n",
      "0  0.416077     39       she   \n",
      "1  0.227181  28153     joyah   \n",
      "2  0.140533  29833    evalle   \n",
      "3  0.007875     24        he   \n",
      "4  0.003686  23512  jaenelle   \n",
      "\n",
      "                                            sequence  \n",
      "0  the nurse is examining the patient. she is wri...  \n",
      "1  the nurse is examining the patient. joyah is w...  \n",
      "2  the nurse is examining the patient. evalle is ...  \n",
      "3  the nurse is examining the patient. he is writ...  \n",
      "4  the nurse is examining the patient. jaenelle i...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"The nurse is examining the patient.  [MASK] is writing down notes.\"))\n",
    "print(  res3   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token token_str  \\\n",
      "0  0.210027     24        he   \n",
      "1  0.208615     39       she   \n",
      "2  0.108849  28153     joyah   \n",
      "3  0.071829  29833    evalle   \n",
      "4  0.010178   1687    doctor   \n",
      "\n",
      "                                            sequence  \n",
      "0  the doctor is examining the patient. he is wri...  \n",
      "1  the doctor is examining the patient. she is wr...  \n",
      "2  the doctor is examining the patient. joyah is ...  \n",
      "3  the doctor is examining the patient. evalle is...  \n",
      "4  the doctor is examining the patient. doctor is...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"The doctor is examining the patient.  [MASK] is writing down notes.\"))\n",
    "print(  res3   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdffe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModel, pipeline, BartTokenizer, BartForConditionalGeneration, BartConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723750b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "model     = BartForConditionalGeneration.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "\n",
    "nlp = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc6e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = '''\n",
    "Aviation is the activities surrounding mechanical flight and the aircraft industry. Aircraft includes fixed-wing and rotary-wing types, \n",
    "morphable wings, wing-less lifting bodies, as well as lighter-than-air craft such as hot air balloons and airships.\n",
    "Aviation began in the 18th century with the development of the hot air balloon, an apparatus capable of atmospheric displacement through buoyancy. \n",
    "Some of the most significant advancements in aviation technology came with the controlled gliding flying of Otto Lilienthal in 1896; then a large \n",
    "step in significance came with the construction of the first powered airplane by the Wright brothers in the early 1900s. Since that time, aviation \n",
    "has been technologically revolutionized by the introduction of the jet which permitted a major form of transport throughout the world.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338830f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Aircraft includes fixed-wing and rotary-wing types, morphable wings, wing-less lifting bodies, and lighter-than-air craft such as hot air balloons and airships . Aviation began in the 18th century with the development of the hot air balloon, an apparatus capable of atmospheric displacement through buoyancy .'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q = nlp(text)\n",
    "\n",
    "print(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d74ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d47cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81690b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence = \"I am going to france\" \n",
    "\n",
    "label = ['travel', 'cooking', 'dancing']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b528921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75379714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "premise    = sequence\n",
    "hypothesis = f'This example is {label}.'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "472d4d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This example is ['travel', 'cooking', 'dancing'].\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "hypothesis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23ea9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\anaconda3\\envs\\py37_ITS530_HF\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2421: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt', truncation_strategy='only_first')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e697abe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   100,   524,   164,     7,  6664,  2389,     2,     2,   713,\n",
       "          1246,    16, 47052, 28881,  3934,   128, 35190,   154,  3934,   128,\n",
       "           417,  7710,   108,  8174,     2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7a66d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits = nli_model(x.to(device))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f56f9cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0327,  1.3776,  0.6796]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee8fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## !pip install datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaea3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from datasets import list_datasets, list_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbcb57c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\anaconda3\\envs\\py37_ITS530_HF\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\user1\\anaconda3\\envs\\py37_ITS530_HF\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: list_metrics is deprecated and will be removed in the next major version of datasets. Use 'evaluate.list_evaluation_modules' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_d = list_datasets()\n",
    "metrics = list_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac667876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of datasets 97007\n",
      "# of metrics 210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"# of datasets\", len(all_d))\n",
    "print(\"# of metrics\", len(metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94a52450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'allenai/ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity', 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'americas_nli', 'ami', 'amttl', 'anli', 'app_reviews', 'aqua_rat', 'aquamuse', 'bigIR/ar_cov19', 'ar_res_reviews', 'ar_sarcasm', 'arabic_billion_words', 'arabic_pos_dialect', 'arabic_speech_corpus', 'arcd', 'arsentd_lev', 'art', 'arxiv_dataset', 'ascent_kb', 'aslg_pc12', 'asnq', 'asset', 'assin', 'assin2', 'atomic', 'autshumato', 'facebook/babi_qa', 'banking77', 'bbaw_egyptian', 'bbc_hindi_nli', 'bc2gm_corpus', 'beans', 'best2009', 'bianet', 'bible_para']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(all_d[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "036277f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score', 'cer', 'character', 'charcut_mt', 'chrf', 'code_eval', 'comet', 'competition_math', 'confusion_matrix', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'mape', 'mase', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'nist_mt', 'pearsonr', 'perplexity', 'poseval', 'precision', 'r_squared', 'recall', 'rl_reliability', 'roc_auc', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'smape', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'trec_eval', 'wer', 'wiki_split', 'xnli', 'xtreme_s', 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'BucketHeadP65/confusion_matrix', 'BucketHeadP65/roc_curve', 'DaliaCaRo/accents_unplugged_eval', 'DarrenChensformer/eval_keyphrase', 'DarrenChensformer/relation_extraction', 'Drunper/metrica_tesi', 'Felipehonorato/eer', 'Fritz02/execution_accuracy', 'GMFTBY/dailydialog_evaluate', 'GMFTBY/dailydialogevaluate', 'He-Xingwei/sari_metric', 'Ikala-allen/relation_extraction', 'JP-SystemsX/nDCG', 'Josh98/nl2bash_m', 'KevinSpaghetti/accuracyk', 'LottieW/accents_unplugged_eval', 'LuckiestOne/valid_efficiency_score', 'Merle456/accents_unplugged_eval', 'Muennighoff/code_eval_octopack', 'NCSOFT/harim_plus', 'Natooz/ece', 'Ndyyyy/bertscore', 'NikitaMartynov/spell-check-metric', 'NimaBoscarino/weat', 'Ochiroo/rouge_mn', 'Pipatpong/perplexity', 'Qui-nn/accents_unplugged_eval', 'RiciHuggingFace/accents_unplugged_eval', 'SpfIo/wer_checker', 'Splend1dchan/cosine_similarity', 'TelEl/accents_unplugged_eval', 'Vallp/ter', 'Vertaix/vendiscore', 'Vickyage/accents_unplugged_eval', 'Viona/fuzzy_reordering', 'Viona/infolm', 'Viona/kendall_tau', 'Vipitis/shadermatch', 'Vlasta/pr_auc', 'Yeshwant123/mcc', 'abdusah/aradiawer', 'abidlabs/mean_iou', 'abidlabs/mean_iou2', 'akki2825/accents_unplugged_eval', 'alvinasvk/accents_unplugged_eval', 'amitness/perplexity', 'andstor/code_perplexity', 'angelasophie/accents_unplugged_eval', 'angelina-wang/directional_bias_amplification', 'anz2/iliauniiccocrevaluation', 'arthurvqin/pr_auc', 'aryopg/roc_auc_skip_uniform_labels', 'bdsaglam/jer', 'boschar/accents_unplugged_eval', 'brian920128/doc_retrieve_metrics', 'bstrai/classification_report', 'bugbounty1806/accuracy', 'cakiki/ndcg', 'carletoncognitivescience/peak_signal_to_noise_ratio', 'chanelcolgate/average_precision', 'chimene/accents_unplugged_eval', 'ckb/unigram', 'codeparrot/apps_metric', 'cpllab/syntaxgym', 'd-matrix/dmx_perplexity', 'daiyizheng/valid', 'danieldux/hierarchical_softmax_loss', 'dayil100/accents_unplugged_eval', 'dayil100/accents_unplugged_eval_WER', 'dgfh76564/accents_unplugged_eval', 'dvitel/codebleu', 'ecody726/bertscore', 'erntkn/dice_coefficient', 'fnvls/bleu1234', 'fnvls/bleu_1234', 'fschlatt/ner_eval', 'gabeorlanski/bc_eval', 'giulio98/code_eval_outputs', 'giulio98/codebleu', 'gjacob/bertimbauscore', 'gjacob/chrf', 'gjacob/google_bleu', 'gjacob/wiki_split', 'gnail/cosine_similarity', 'gorkaartola/metric_for_tp_fp_samples', 'guydav/restrictedpython_code_eval', 'hack/test_metric', 'harshhpareek/bertscore', 'hpi-dhc/FairEval', 'huanghuayu/multiclass_brier_score', 'hynky/sklearn_proxy', 'hyperml/balanced_accuracy', 'idsedykh/codebleu', 'idsedykh/codebleu2', 'idsedykh/megaglue', 'idsedykh/metric', 'illorca/FairEval', 'ingyu/klue_mrc', 'jjkim0807/code_eval', 'jordyvl/ece', 'jpxkqx/peak_signal_to_noise_ratio', 'jpxkqx/signal_to_reconstruction_error', 'juliakaczor/accents_unplugged_eval', 'jzm-mailchimp/joshs_second_test_metric', 'k4black/codebleu', 'kashif/mape', 'kedudzic/charmatch', 'kyokote/my_metric2', 'langdonholmes/cohen_weighted_kappa', 'leslyarun/fbeta_score', 'lhy/hamming_loss', 'lhy/ranking_loss', 'livvie/accents_unplugged_eval', 'loubnabnl/apps_metric2', 'lvwerra/accuracy_score', 'lvwerra/bary_score', 'lvwerra/test', 'manueldeprada/beer', 'mfumanelli/geometric_mean', 'mgfrantz/roc_auc_macro', 'mtc/fragments', 'nevikw39/specificity', 'nlpln/tst', 'ola13/precision_at_k', 'omidf/squad_precision_recall', 'posicube/mean_reciprocal_rank', 'repllabs/mean_average_precision', 'repllabs/mean_reciprocal_rank', 'ronaldahmed/nwentfaithfulness', 'sakusakumura/bertscore', 'shalakasatheesh/squad', 'shalakasatheesh/squad_v2', 'shirayukikun/sescore', 'shunzh/apps_metric', 'sma2023/wil', 'sportlosos/sescore', 'transZ/sbert_cosine', 'transZ/test_parascore', 'transformersegmentation/segmentation_scores', 'unitxt/metric', 'unnati/kendall_tau_distance', 'vichyt/metric-codebleu', 'weiqis/pajm', 'xu1998hz/sescore', 'xu1998hz/sescore_english_coco', 'xu1998hz/sescore_english_mt', 'xu1998hz/sescore_english_webnlg', 'xu1998hz/sescore_german_mt', 'ybelkada/cocoevaluate', 'yonting/average_precision_score', 'yqsong/execution_accuracy', 'yulong-me/yl_metric', 'yuyijiong/quad_match_score', 'yzha/ctc_eval', 'zbeloki/m2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2fb5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29acde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f3ff1dbbb54cde88e0670bf2fbbf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\anaconda3\\envs\\py37_ITS530_HF\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user1\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476e16bfeecf41278fe725b0f0ac6af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4679e281e04d77a75f5fb2fa9158c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ecf782027e4e628fc383f455452eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(     pipeline('sentiment-analysis')('we love you')          )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e3b1f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9988259673118591}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(     pipeline('sentiment-analysis')('we hate you')          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c386748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9996534585952759}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(     pipeline('sentiment-analysis')('my cat kind of likes you')          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ce8b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9846875071525574}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(     pipeline('sentiment-analysis')('i am going to the store')          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7033cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.8937287926673889}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(     pipeline('sentiment-analysis')('bacon')          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88011c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9635980725288391}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(     pipeline('sentiment-analysis')('the')          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecba8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e61fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0c1889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "885e3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sequence_to_classify = \"i like that tobacco rates have fallen\"\n",
    "\n",
    "candidate_labels = ['cars', 'smoking', 'pets']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9e7f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = classifier(sequence_to_classify, candidate_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c7bfe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'i like that tobacco rates have fallen', 'labels': ['smoking', 'pets', 'cars'], 'scores': [0.9401767253875732, 0.034628964960575104, 0.025194309651851654]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a600d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2cd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ef649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa2667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b9ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcfd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473444c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f42ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4654de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa014b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c95d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0372f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c10f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
