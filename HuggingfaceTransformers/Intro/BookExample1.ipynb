{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52cb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from transformers import AutoModel\n",
    "\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1144a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875db974ace04c80b9daafe41eedd675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\anaconda3\\envs\\huggingface\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user1\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3863efe8b74146b13a6ecc26ef1656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc23bb9b89e4192b151f42cc30abc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2478, 19081, 2003, 3733, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = \"Using transformers is easy!\"\n",
    "\n",
    "print(    tokenizer(text)    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac640d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2478, 19081,  2003,  3733,   999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")   ## pt is for pytorch tensors\n",
    "\n",
    "print(  encoded_input   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80d907d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4860a79880804bf4bee8e725b643be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0245,  0.1256,  0.1062,  ..., -0.0637,  0.0344,  0.3892],\n",
      "         [ 0.2678,  0.3460, -0.3190,  ..., -0.1258,  0.1899,  0.2213],\n",
      "         [ 1.8175, -0.0306, -0.1497,  ..., -0.4804, -0.1272,  0.4366],\n",
      "         ...,\n",
      "         [-0.0793,  0.1282,  0.1530,  ...,  0.0619, -0.0437,  0.0854],\n",
      "         [-0.5069, -0.3263, -0.0349,  ...,  0.6772,  0.0161, -0.0475],\n",
      "         [ 0.7605,  0.1723, -0.0956,  ...,  0.3013, -0.4924, -0.2380]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-8.0693e-01, -2.2955e-01, -7.8098e-02,  5.0498e-01, -5.4595e-02,\n",
      "          4.6806e-03,  7.9700e-01,  1.5625e-01, -2.2330e-02, -9.9973e-01,\n",
      "         -9.3650e-02,  2.7417e-01,  9.7285e-01, -9.1490e-02,  8.9556e-01,\n",
      "         -4.5264e-01, -9.2253e-03, -5.1343e-01,  1.1915e-01, -5.0694e-01,\n",
      "          5.1190e-01,  9.9036e-01,  4.3037e-01,  2.3087e-01,  2.4903e-01,\n",
      "          4.4874e-01, -5.5464e-01,  8.9291e-01,  9.3205e-01,  6.3521e-01,\n",
      "         -5.6062e-01,  1.5136e-01, -9.7535e-01, -1.0466e-01, -8.7350e-03,\n",
      "         -9.6917e-01,  2.3301e-01, -6.6448e-01,  1.3110e-01,  4.0307e-02,\n",
      "         -8.4948e-01,  9.2704e-02,  9.9731e-01, -6.5108e-01,  9.2232e-03,\n",
      "         -3.0088e-01, -9.9990e-01,  5.3405e-02, -8.2420e-01,  6.9862e-02,\n",
      "          1.5873e-01, -2.9166e-01,  1.0858e-01,  3.1045e-01,  3.5964e-01,\n",
      "          1.9965e-01, -2.5448e-01, -8.5427e-03, -9.1700e-02, -4.0565e-01,\n",
      "         -5.8833e-01,  2.1108e-01, -1.7970e-01, -8.1340e-01,  1.6097e-01,\n",
      "         -7.7431e-02,  5.0666e-02, -1.7087e-01,  2.8893e-02, -1.6621e-02,\n",
      "          8.0907e-01,  8.7130e-02,  3.7305e-02, -7.7836e-01, -1.5121e-01,\n",
      "          1.3257e-01, -4.1371e-01,  1.0000e+00, -1.6688e-01, -9.5741e-01,\n",
      "         -1.3882e-02,  1.2986e-01,  3.1587e-01,  3.8013e-01, -1.6050e-01,\n",
      "         -9.9999e-01,  1.9682e-01, -2.3730e-02, -9.7978e-01,  1.7979e-01,\n",
      "          2.6340e-01, -1.2108e-01,  8.1585e-03,  3.6060e-01, -2.1808e-01,\n",
      "         -1.4638e-01, -1.3528e-01, -1.9099e-01, -3.3304e-02, -1.4138e-02,\n",
      "         -1.2780e-01, -7.7660e-02, -5.6965e-03, -2.9172e-01,  9.7807e-02,\n",
      "         -3.3428e-01, -3.8657e-01,  2.6733e-01, -2.6927e-01,  5.7803e-01,\n",
      "          2.5838e-01, -1.9271e-01,  2.0445e-01, -9.3075e-01,  5.1738e-01,\n",
      "         -1.4734e-01, -9.7571e-01, -3.6683e-01, -9.7983e-01,  4.9812e-01,\n",
      "         -9.0744e-02, -7.2502e-02,  9.3019e-01,  3.9441e-01,  2.2934e-01,\n",
      "          8.5643e-02,  1.4300e-01, -1.0000e+00, -1.7908e-01, -2.4885e-01,\n",
      "          1.4101e-01, -1.0805e-01, -9.5851e-01, -9.3664e-01,  4.5034e-01,\n",
      "          9.3644e-01,  1.3158e-01,  9.9654e-01, -3.9841e-02,  8.9691e-01,\n",
      "          1.9111e-01, -7.9264e-02, -2.4080e-01, -3.2739e-01,  4.5909e-01,\n",
      "          2.5007e-03, -4.6659e-01,  1.9817e-01,  1.3912e-01, -3.3462e-01,\n",
      "         -3.3291e-01, -9.8980e-02,  2.2952e-03, -9.1728e-01, -2.6936e-01,\n",
      "          8.9525e-01,  2.2041e-01, -6.2468e-02,  5.1193e-01, -9.5714e-02,\n",
      "         -3.0350e-01,  7.5995e-01,  3.6758e-01,  2.4042e-01, -3.2262e-02,\n",
      "          2.4398e-01, -2.1624e-01,  4.2241e-01, -7.8136e-01,  3.1716e-01,\n",
      "          2.1915e-01, -2.1981e-01, -4.8427e-02, -9.5833e-01, -2.1616e-01,\n",
      "          4.1545e-01,  9.7993e-01,  7.2754e-01,  1.6402e-01,  1.8560e-01,\n",
      "         -1.2295e-01,  6.6035e-02, -9.1547e-01,  9.6345e-01, -4.9247e-02,\n",
      "          1.2726e-01,  1.3058e-01,  6.5870e-02, -8.1989e-01, -3.7575e-01,\n",
      "          7.5660e-01, -8.3923e-02, -7.2467e-01,  1.6125e-01, -3.4961e-01,\n",
      "         -3.0578e-01, -2.0488e-02,  2.2186e-01, -1.7275e-01, -2.9424e-01,\n",
      "          2.4525e-02,  8.9628e-01,  9.2672e-01,  6.9406e-01, -4.4220e-01,\n",
      "          4.5836e-01, -8.5466e-01, -3.8480e-01, -4.4047e-02,  1.7052e-01,\n",
      "         -8.2675e-02,  9.8684e-01, -2.7132e-01, -2.8912e-02, -8.6806e-01,\n",
      "         -9.7365e-01, -1.0019e-01, -8.4460e-01,  6.3547e-02, -6.4409e-01,\n",
      "          2.6812e-01,  4.5650e-01, -9.2767e-02,  2.0368e-01, -9.3706e-01,\n",
      "         -6.5065e-01,  2.6622e-01, -2.2203e-01,  3.5747e-01, -2.0383e-01,\n",
      "          4.3871e-01,  1.4815e-01, -5.1123e-01,  6.2445e-01,  8.8006e-01,\n",
      "          8.8060e-02, -6.4801e-01,  7.1853e-01, -1.6384e-01,  7.8464e-01,\n",
      "         -4.7550e-01,  9.5512e-01,  1.3076e-01,  4.3126e-01, -8.7076e-01,\n",
      "          2.3859e-02, -8.1405e-01,  1.5223e-01,  8.9342e-02, -4.2130e-01,\n",
      "          1.5582e-01,  4.0571e-01,  1.9589e-01,  7.0439e-01, -3.0846e-01,\n",
      "          9.8070e-01, -6.0916e-01, -9.1614e-01, -1.7916e-02, -4.8824e-02,\n",
      "         -9.7768e-01,  1.7690e-01,  2.1155e-01, -4.2166e-01, -2.6435e-01,\n",
      "         -4.8533e-01, -9.2835e-01,  7.5747e-01, -1.8330e-04,  9.6480e-01,\n",
      "          6.5538e-02, -8.1384e-01, -2.1544e-01, -8.9222e-01, -2.4304e-01,\n",
      "         -2.4165e-02,  3.3696e-01, -1.5462e-01, -9.3290e-01,  3.7076e-01,\n",
      "          4.5001e-01,  3.5216e-01,  5.0091e-02,  9.8980e-01,  9.9975e-01,\n",
      "          9.5633e-01,  8.5565e-01,  7.9330e-01, -9.7050e-01, -2.4648e-01,\n",
      "          9.9988e-01, -5.8991e-01, -9.9998e-01, -8.8661e-01, -3.3174e-01,\n",
      "          3.5820e-01, -1.0000e+00, -1.0059e-01,  1.0458e-01, -8.7745e-01,\n",
      "         -2.2353e-02,  9.6624e-01,  9.6099e-01, -1.0000e+00,  7.4753e-01,\n",
      "          8.9533e-01, -4.5733e-01,  4.5401e-01, -1.0749e-01,  9.4313e-01,\n",
      "          4.1960e-01,  3.1564e-01, -9.0901e-02,  2.3180e-01, -4.0300e-01,\n",
      "         -7.4911e-01,  1.8190e-01,  5.0469e-02,  8.4004e-01, -2.4601e-03,\n",
      "         -6.1238e-01, -8.7067e-01, -3.6567e-02, -1.4675e-01, -4.0689e-01,\n",
      "         -9.4310e-01, -5.4568e-02, -2.2922e-01,  4.7034e-01, -8.4271e-04,\n",
      "          1.6473e-01, -6.1009e-01,  9.5913e-02, -5.1800e-01,  3.4012e-01,\n",
      "          4.9001e-01, -8.9927e-01, -4.8331e-01,  1.5024e-01, -4.1442e-01,\n",
      "          3.2478e-02, -9.3292e-01,  9.4318e-01, -1.5642e-01, -2.2795e-01,\n",
      "          1.0000e+00, -8.9335e-02, -7.4984e-01,  2.1740e-01,  5.3060e-02,\n",
      "          1.2262e-02,  1.0000e+00,  4.5659e-01, -9.6248e-01, -3.3499e-01,\n",
      "          2.7310e-01, -3.0940e-01, -3.1532e-01,  9.9502e-01, -1.3470e-01,\n",
      "          1.0798e-02,  2.8401e-01,  9.5626e-01, -9.7733e-01,  7.7631e-01,\n",
      "         -8.5197e-01, -9.3308e-01,  9.3958e-01,  9.0363e-01, -2.4957e-01,\n",
      "         -5.3120e-01, -7.3842e-02, -6.7206e-02,  1.4951e-01, -9.1531e-01,\n",
      "          3.3933e-01,  3.3719e-01, -4.4206e-02,  8.1836e-01, -7.0472e-01,\n",
      "         -3.7476e-01,  2.1586e-01, -1.3151e-01,  2.8981e-01,  7.6345e-02,\n",
      "          3.2799e-01, -1.0584e-01, -4.8380e-02, -1.5923e-01, -3.1009e-01,\n",
      "         -9.4464e-01, -1.0402e-01,  1.0000e+00,  7.8810e-02, -3.8804e-02,\n",
      "         -1.5313e-01, -1.0382e-02, -3.6609e-01,  4.0297e-01,  3.2693e-01,\n",
      "         -8.5416e-02, -7.7358e-01,  1.5549e-02, -8.7544e-01, -9.7545e-01,\n",
      "          6.4336e-01,  1.1659e-01, -1.9802e-01,  9.9840e-01,  1.8976e-01,\n",
      "          7.6887e-02, -1.1438e-01,  6.0018e-01, -2.9937e-02,  4.1683e-01,\n",
      "          8.6059e-02,  9.6045e-01, -1.4988e-01,  3.7188e-01,  7.5653e-01,\n",
      "         -1.1260e-01, -2.0171e-01, -4.6066e-01, -1.8401e-02, -9.0042e-01,\n",
      "          2.3770e-01, -9.0984e-01,  9.3333e-01,  5.1747e-02,  3.0526e-01,\n",
      "          8.7149e-02, -1.1829e-02,  1.0000e+00, -4.2711e-01,  5.0115e-01,\n",
      "         -5.3655e-02,  6.9584e-01, -9.6526e-01, -6.8838e-01, -2.7324e-01,\n",
      "          5.4192e-02,  1.5302e-02, -1.8431e-01,  1.1719e-01, -9.4914e-01,\n",
      "          1.1118e-02, -1.8535e-01, -9.4378e-01, -9.7960e-01,  3.9752e-01,\n",
      "          6.5870e-01, -9.1114e-02, -6.2071e-01, -4.9771e-01, -5.1922e-01,\n",
      "         -2.3533e-02, -1.3315e-02, -9.0396e-01,  4.8514e-01, -1.1471e-01,\n",
      "          3.1671e-01, -9.0658e-02,  4.1215e-01, -9.0740e-02,  8.1691e-01,\n",
      "          2.4675e-01,  1.2968e-01,  3.0002e-03, -6.9687e-01,  7.1903e-01,\n",
      "         -7.0665e-01, -1.1214e-01, -1.0464e-01,  1.0000e+00, -2.1131e-01,\n",
      "          1.9290e-01,  7.0170e-01,  5.0720e-01, -2.1303e-02,  7.6784e-02,\n",
      "          2.3659e-01,  6.9486e-02,  5.8781e-02,  1.3068e-01, -4.6417e-01,\n",
      "         -2.5202e-01,  4.7214e-01, -9.7722e-02, -1.9600e-01,  6.6032e-01,\n",
      "          3.3888e-01,  1.8278e-02,  3.3838e-02, -1.1809e-01,  9.9396e-01,\n",
      "          6.8474e-02,  4.0136e-02, -3.2415e-01,  7.9705e-02, -1.7239e-01,\n",
      "         -2.0474e-01,  9.9999e-01,  1.6814e-01,  3.7092e-02, -9.7786e-01,\n",
      "         -9.2082e-03, -8.5347e-01,  9.9918e-01,  7.4692e-01, -7.1508e-01,\n",
      "          3.4106e-01,  2.9014e-01, -1.0467e-01,  5.5030e-01,  3.2316e-02,\n",
      "         -2.2904e-01,  1.2492e-01,  6.2244e-02,  9.3175e-01, -3.9400e-01,\n",
      "         -9.4904e-01, -5.4308e-01,  2.0346e-01, -9.2968e-01,  9.7265e-01,\n",
      "         -3.7871e-01, -1.2349e-01, -2.4950e-01,  4.7224e-01,  2.8212e-01,\n",
      "         -1.8212e-01, -9.6503e-01, -9.2420e-02, -7.0992e-02,  9.1386e-01,\n",
      "          6.3773e-02, -3.6354e-01, -8.6207e-01, -1.3284e-01,  2.8337e-02,\n",
      "         -7.2289e-02, -8.9489e-01,  9.4697e-01, -9.5790e-01,  3.6471e-01,\n",
      "          9.9998e-01,  3.1712e-01, -4.8636e-01, -2.7477e-02, -3.4102e-01,\n",
      "          2.1831e-01, -9.3478e-02,  4.5264e-01, -9.2096e-01, -2.0185e-01,\n",
      "         -6.8922e-02,  1.4302e-01, -1.1499e-01,  3.0689e-01,  6.4045e-01,\n",
      "          1.7534e-01, -3.1930e-01, -4.2536e-01,  1.5577e-01,  2.5666e-01,\n",
      "          6.6747e-01, -1.6247e-01,  2.7846e-02,  3.5049e-02, -3.7073e-02,\n",
      "         -8.3882e-01, -1.6867e-01, -6.7778e-02, -9.9383e-01,  6.0389e-01,\n",
      "         -1.0000e+00, -3.6400e-01, -4.3181e-01, -1.3990e-01,  7.4709e-01,\n",
      "          2.4853e-01,  8.5506e-02, -6.8283e-01, -1.0749e-01,  7.3225e-01,\n",
      "          6.4275e-01, -1.1077e-02,  3.6798e-01, -6.0260e-01,  6.6456e-02,\n",
      "         -4.9960e-03,  1.2260e-01,  1.5128e-01,  7.4629e-01, -1.1590e-01,\n",
      "          1.0000e+00,  1.0917e-01, -3.3361e-01, -9.2606e-01,  1.7550e-01,\n",
      "         -7.6893e-02,  9.9993e-01, -7.9612e-01, -9.2217e-01,  2.0935e-01,\n",
      "         -3.9006e-01, -7.3423e-01,  1.2146e-01, -1.3270e-01, -5.3680e-01,\n",
      "         -2.6603e-01,  9.1959e-01,  7.7091e-01, -4.1181e-01,  2.6311e-01,\n",
      "         -2.2255e-01, -2.7543e-01, -1.3545e-01,  6.9295e-02,  9.7576e-01,\n",
      "          2.3980e-01,  8.3575e-01,  5.5182e-01,  5.2120e-02,  9.5429e-01,\n",
      "          3.8379e-02,  3.8238e-01,  3.0231e-02,  9.9999e-01,  1.9562e-01,\n",
      "         -8.6649e-01,  4.8111e-01, -9.6812e-01, -8.0678e-02, -9.0729e-01,\n",
      "          1.3852e-01,  3.4657e-02,  8.2973e-01, -1.3381e-01,  9.2618e-01,\n",
      "          2.3641e-01, -1.1484e-01,  6.7370e-02,  4.6496e-01,  2.0901e-01,\n",
      "         -8.6575e-01, -9.7216e-01, -9.7511e-01,  2.1821e-01, -2.9150e-01,\n",
      "          9.9907e-02,  1.6243e-01, -2.8210e-03,  1.9700e-01,  3.2306e-01,\n",
      "         -9.9999e-01,  8.8178e-01,  2.0983e-01,  1.1092e-01,  9.3068e-01,\n",
      "          3.0156e-01,  2.5755e-01,  2.0259e-01, -9.7336e-01, -9.2025e-01,\n",
      "         -2.5134e-01, -8.8316e-02,  6.6548e-01,  4.6846e-01,  8.1476e-01,\n",
      "          1.9317e-01, -4.2984e-01, -1.6354e-01,  2.7414e-01, -5.0309e-01,\n",
      "         -9.8432e-01,  2.7842e-01,  1.0795e-01, -8.9846e-01,  9.3812e-01,\n",
      "         -3.7096e-01, -7.3985e-02,  4.2313e-01, -1.6020e-01,  9.0063e-01,\n",
      "          6.5636e-01,  2.0661e-01,  9.4530e-02,  2.8253e-01,  8.1507e-01,\n",
      "          9.0654e-01,  9.6963e-01, -1.2809e-01,  6.4264e-01,  2.2661e-01,\n",
      "          2.8017e-01,  6.7664e-01, -9.0934e-01,  1.4490e-02, -1.4224e-02,\n",
      "         -4.4035e-02,  1.2798e-01, -1.0869e-01, -9.0210e-01,  5.6138e-01,\n",
      "         -5.1869e-02,  4.4514e-01, -2.4095e-01,  2.1980e-01, -3.1606e-01,\n",
      "         -6.0214e-02, -6.3803e-01, -3.1309e-01,  4.3863e-01,  1.2491e-01,\n",
      "          8.7836e-01,  4.4623e-01,  4.5004e-02, -3.6396e-01, -2.1821e-02,\n",
      "          2.7998e-02, -8.9432e-01,  8.4768e-01,  4.0873e-03,  3.6565e-01,\n",
      "          1.1024e-01, -1.6959e-01,  7.8012e-01, -2.4000e-01, -2.4772e-01,\n",
      "         -2.2759e-01, -6.5326e-01,  7.4380e-01, -4.9723e-02, -3.8314e-01,\n",
      "         -4.1102e-01,  5.3696e-01,  2.0416e-01,  9.9133e-01, -6.7996e-02,\n",
      "         -1.8402e-01, -1.9683e-01, -2.2829e-01,  1.6786e-01, -2.1096e-01,\n",
      "         -9.9999e-01,  2.4763e-01, -1.7585e-02,  1.3428e-01,  3.6199e-02,\n",
      "          1.3687e-01, -3.4179e-02, -9.5323e-01, -1.6859e-01,  1.8482e-01,\n",
      "          5.6347e-02, -4.5788e-01, -1.9958e-01,  3.4789e-01,  3.8013e-01,\n",
      "          5.0409e-01,  7.7521e-01,  2.5048e-01,  4.4049e-01,  4.6310e-01,\n",
      "         -1.2782e-01, -5.6950e-01,  8.4918e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "output = model(**encoded_input)\n",
    "\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e09212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f205aadbc6014c309d0c6f85f6647a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.09747550636529922, 'token': 10533, 'token_str': 'carpenter', 'sequence': 'the man worked as a carpenter.'}, {'score': 0.052383385598659515, 'token': 15610, 'token_str': 'waiter', 'sequence': 'the man worked as a waiter.'}, {'score': 0.04962700605392456, 'token': 13362, 'token_str': 'barber', 'sequence': 'the man worked as a barber.'}, {'score': 0.037886135280132294, 'token': 15893, 'token_str': 'mechanic', 'sequence': 'the man worked as a mechanic.'}, {'score': 0.03768078237771988, 'token': 18968, 'token_str': 'salesman', 'sequence': 'the man worked as a salesman.'}]\n",
      "      score  token  token_str                        sequence\n",
      "0  0.097476  10533  carpenter  the man worked as a carpenter.\n",
      "1  0.052383  15610     waiter     the man worked as a waiter.\n",
      "2  0.049627  13362     barber     the man worked as a barber.\n",
      "3  0.037886  15893   mechanic   the man worked as a mechanic.\n",
      "4  0.037681  18968   salesman   the man worked as a salesman.\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "result = unmasker(\"the man worked as a [MASK].\")     \n",
    "\n",
    "print(result)\n",
    "\n",
    "print(   pd.DataFrame(result)     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a9528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
