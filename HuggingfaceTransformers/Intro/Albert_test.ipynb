{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5de0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install SentencePiece\n",
    "## !pip install torch\n",
    "## !pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d192679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c66062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "model     = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660f11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 1.0939,  0.5053,  0.1715,  ..., -0.4915, -0.7119,  1.1999],\n",
      "         [ 0.1346,  1.4558,  1.0297,  ..., -0.2366,  1.0784, -0.2260],\n",
      "         [-0.7314, -0.7786, -0.3179,  ...,  0.1351,  1.5941, -0.9347],\n",
      "         ...,\n",
      "         [-0.3901, -0.3225,  0.5177,  ...,  0.1546,  1.4358,  0.5165],\n",
      "         [ 0.6785,  0.1826,  0.2188,  ..., -0.4804,  1.1837,  0.4180],\n",
      "         [ 0.0544,  0.1334, -0.0490,  ..., -0.1220,  0.1077,  0.1971]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5389, -0.6086,  0.8374, -0.8752, -0.6615, -0.9479,  0.5728, -0.5487,\n",
      "          0.5840, -0.9994,  0.8545,  0.5818, -0.5577, -0.9433, -0.9580, -0.5357,\n",
      "          0.6166,  0.5180,  0.9972, -0.5242, -0.7181, -0.9925,  0.9959,  0.9557,\n",
      "          0.5715, -0.5299,  0.6058, -0.9689, -0.9995, -0.5381, -1.0000,  0.6917,\n",
      "          0.5956,  0.5521,  0.5793, -0.4755,  0.6820,  0.9975, -0.6022,  0.6362,\n",
      "          0.5400, -0.9743, -0.7325,  0.6179,  0.5656,  0.5581,  0.9794, -0.9897,\n",
      "          0.8847, -0.5357, -0.5040, -0.4795, -0.5231, -0.9948, -0.4365,  0.6682,\n",
      "         -0.6268, -0.5502,  0.9999, -0.9274,  0.5563, -0.7180,  0.6925, -0.0518,\n",
      "         -0.5860,  0.5159,  0.5491,  0.9987, -0.4818,  0.9509,  0.5379,  0.6610,\n",
      "          0.3893, -0.7199,  0.9678,  0.6112,  0.2541,  0.5337, -0.1678, -0.9875,\n",
      "          0.7976,  0.6921, -0.6272,  0.6089, -0.9083, -0.9670,  0.7986, -0.9999,\n",
      "          0.6013,  0.9556,  0.5744,  0.6996, -0.5221, -1.0000,  0.4949, -0.6163,\n",
      "         -0.9996,  0.6177,  0.4992, -0.6089,  0.0204, -0.4823,  0.6955, -0.6689,\n",
      "         -0.5657, -0.5609,  0.5371,  0.9156,  0.5947,  0.9987, -0.9881, -0.5697,\n",
      "          0.5092,  0.9699, -0.5373,  0.2463, -0.6231,  0.8376, -0.9970,  0.6121,\n",
      "          0.5532, -0.1323,  0.5625, -0.2801,  0.5866, -0.0411,  0.4946, -0.5807,\n",
      "          0.9781, -0.7949,  0.7598,  0.4959, -0.9996, -0.2695,  0.5900,  0.9567,\n",
      "         -0.5043, -0.5384, -0.4652,  0.5677,  0.9913, -0.5343,  0.4876, -0.6243,\n",
      "         -0.5905,  0.5376,  0.1107, -0.4722,  0.5395,  0.9920, -0.9649,  0.9803,\n",
      "          0.6290, -0.9754, -0.9965,  0.4031,  0.9585, -0.8586,  0.7727, -0.6127,\n",
      "         -0.5031, -0.8986, -0.9972, -0.6447, -0.9983, -0.6674,  0.9995, -0.0982,\n",
      "          0.9989, -0.9960, -0.5467,  0.6419, -0.5579,  0.9756,  0.5637,  0.5709,\n",
      "          0.5049,  0.7744, -0.6163, -0.4750,  0.9860, -0.9988,  0.5437,  0.6146,\n",
      "          0.9866,  0.5762,  0.6972, -0.8261,  0.5362, -0.7132, -0.5479, -0.8171,\n",
      "          0.6692,  0.8044,  1.0000, -0.6661,  0.9877, -0.9413,  0.9603, -0.9974,\n",
      "         -0.5681,  0.8138,  0.9554,  0.6140,  0.6060,  0.9017, -0.9037, -0.9976,\n",
      "         -1.0000, -0.5775, -0.9990,  0.9761, -0.9929,  0.5654, -0.9995,  0.9895,\n",
      "          0.9828, -0.5895,  0.9999, -0.5955,  0.7423,  0.5605, -1.0000,  0.9405,\n",
      "          0.4755,  0.5402, -0.0427, -0.5301,  0.9834, -0.9979, -0.9650, -0.1920,\n",
      "          0.6147, -0.9998, -0.7863, -0.5956,  0.6833,  0.6220,  0.6133, -0.9984,\n",
      "          0.9997,  0.5902, -0.4455, -0.5963, -0.4481,  1.0000, -0.6990, -0.9864,\n",
      "         -0.5737,  0.9986,  0.9650,  0.6409,  0.7254, -0.5913,  0.7585, -0.4945,\n",
      "         -0.9905, -0.9907, -0.9885,  0.5429, -0.9832,  0.3368, -0.4427, -0.9990,\n",
      "         -0.5921,  0.8455,  0.9974,  0.9907,  0.5569, -0.7269,  0.5541, -0.5849,\n",
      "          0.9503, -0.3441,  0.9727, -0.5766, -0.9643,  0.6135,  0.6478,  0.5075,\n",
      "         -0.6038, -0.9645,  0.6113, -0.5924,  0.9977, -0.8475,  0.9993, -0.9840,\n",
      "         -0.9997,  0.5611, -0.6752, -0.5998,  0.9976, -0.5602, -0.9991, -0.9998,\n",
      "          0.5379,  0.9600,  0.9109, -0.9273,  0.6442, -0.5728, -0.5806,  0.9976,\n",
      "          0.6053, -0.5299, -0.4652,  0.5691,  0.5444,  0.7444, -0.7575, -0.5889,\n",
      "         -0.6324, -0.9904, -0.6146, -0.1315, -0.5207, -0.7519,  0.9885,  0.9849,\n",
      "         -0.5481, -0.7331,  0.9983, -0.9965,  0.6848, -1.0000,  0.8843, -0.9998,\n",
      "         -0.9986, -0.4946, -0.8764, -0.5258, -0.6298, -0.9630,  0.5616, -0.9943,\n",
      "          0.5348, -0.6639,  0.9751,  0.9655, -0.9999, -0.5451, -0.9690,  0.4979,\n",
      "          0.6217,  0.5347,  0.5720, -0.4130,  0.6365, -0.9977,  0.5660,  0.8981,\n",
      "         -0.6503,  0.8731, -0.5977,  0.5923, -0.9534, -0.6619, -0.5056,  0.9936,\n",
      "          0.9946, -0.8731, -0.5158,  0.5799, -0.8774,  0.9835, -0.9888,  0.9781,\n",
      "         -0.9987, -0.6409, -0.9903,  0.9985,  0.9770, -0.0145, -0.6365, -0.8916,\n",
      "         -0.9632,  0.6548, -0.5847, -0.4420, -0.5395,  0.9907,  0.5294,  0.9598,\n",
      "         -0.8369,  0.3878,  0.4403,  0.8903, -0.9897,  0.9904, -0.9379, -0.5925,\n",
      "          0.7264,  1.0000, -0.6151,  0.5495, -0.9939, -0.9947, -0.6024,  0.5712,\n",
      "          0.9903, -0.5553, -0.8521,  0.9633,  0.9941, -0.9958,  0.6838,  0.9977,\n",
      "          0.9777,  0.6092,  0.6768,  0.9565,  0.8763,  0.5598,  0.9858, -0.5119,\n",
      "          0.9999, -0.9974, -0.9997,  0.9946, -0.5673,  0.9900, -0.3811,  0.5111,\n",
      "         -0.5730,  0.6244, -0.6128, -0.5874,  0.5110,  0.7326,  0.6362,  0.9932,\n",
      "          0.4849, -0.9857, -1.0000, -0.4840,  0.7177,  0.7035, -0.5624,  0.9677,\n",
      "         -0.5916,  0.3152, -0.6548, -0.6172,  0.5814, -0.9997,  1.0000, -0.9984,\n",
      "          0.9956, -0.5522,  0.9703,  0.8778,  0.9980, -0.6644, -1.0000, -0.6022,\n",
      "         -0.9981,  0.6386, -0.5405, -0.9466, -0.5577,  0.7479, -0.5130,  0.9974,\n",
      "          0.6783, -0.6663, -0.9988,  1.0000, -0.8558, -0.9997,  0.5939,  0.5842,\n",
      "          0.7857,  0.5055,  0.4649,  0.5300, -0.7545, -0.5991,  0.9925, -0.9735,\n",
      "          0.6699, -0.9737,  0.9788, -0.6243, -0.1971,  0.9100,  0.9976,  0.9965,\n",
      "         -0.5905, -1.0000, -0.9894, -0.9985, -0.9902,  0.5256, -0.9414,  0.8575,\n",
      "         -0.5909, -0.5276,  0.9843,  0.5991, -0.5081, -0.5691, -0.9928, -0.8762,\n",
      "         -0.5308, -0.8378,  0.6305, -0.9992, -0.7223, -0.9795, -0.9966, -0.2209,\n",
      "         -0.9893,  0.5206, -0.9999,  0.1896, -0.5885, -0.2791, -0.5350,  0.6116,\n",
      "          0.5779, -0.5441,  0.5181,  0.9797, -0.6044,  1.0000,  0.9804,  0.9325,\n",
      "          0.6564, -0.5283, -0.5807,  0.9990, -0.5780, -0.3293,  0.8932, -0.9560,\n",
      "          0.2547, -0.9955,  0.9760, -0.7774, -0.9482, -0.9731, -0.6382, -1.0000,\n",
      "         -0.9998, -0.9997,  0.6137,  0.9058, -0.9950,  0.9975,  0.7070, -0.7353,\n",
      "          0.9996,  0.6472, -0.9668,  0.4811, -0.5817,  0.9999, -0.5038,  0.9689,\n",
      "         -0.6226, -0.9957,  0.7648,  0.8525, -0.5277, -0.5593, -0.9321, -0.8895,\n",
      "          0.0924, -0.5239,  0.6398,  1.0000, -0.8751,  0.5711, -0.6633,  0.6174,\n",
      "         -0.9837,  0.5024, -0.3760, -0.0277, -0.9935, -0.9125,  0.9988,  0.5705,\n",
      "          0.6303,  0.5907,  0.6922, -0.4449,  0.9999, -0.9999, -0.4663,  0.5208,\n",
      "         -0.7330,  0.7680, -0.5072, -0.6962,  0.4947,  0.9871, -0.5109,  0.9981,\n",
      "         -0.2512,  0.6404,  0.6248,  0.5514,  0.4868,  0.9998,  0.6474, -0.8779,\n",
      "         -0.5295, -0.5331, -0.5324,  0.9995,  0.9986, -0.9297, -0.8414, -0.4643,\n",
      "         -0.9900,  0.9704,  0.3923,  0.9969,  0.9962,  0.6685, -0.4709, -0.9802,\n",
      "          0.9997,  0.9108, -0.5998,  0.7974,  0.6599, -0.5918,  0.2114,  0.8868,\n",
      "         -0.9023,  0.4456,  0.6417,  0.9894,  0.9965, -0.5891,  0.7945, -1.0000,\n",
      "         -0.5476,  0.9729, -0.9571,  0.6201,  0.9929, -1.0000, -0.5281, -0.5658,\n",
      "          0.9561,  0.9945,  0.4898,  0.5265, -0.4376, -0.6331,  0.9994,  0.5002,\n",
      "         -0.6261,  0.9982, -0.6541, -0.5192,  0.6054,  0.6585,  0.9997,  0.9172,\n",
      "         -0.9721, -0.5747,  0.5340, -0.6338,  0.9969, -0.9998, -0.5476,  0.3739,\n",
      "         -0.9095,  0.4989,  0.7928,  0.6511, -0.6124, -0.9995,  0.5622,  0.9802,\n",
      "          0.6183,  0.9917,  0.5452, -0.3209,  0.6751,  0.8842, -0.0295,  0.8924,\n",
      "         -0.9983,  0.5719, -0.9400,  0.5640, -0.6941, -0.9860, -0.7384,  0.5401,\n",
      "          0.9944,  0.6418,  0.6126,  0.4074, -0.6566,  0.5857,  0.5752,  0.4527,\n",
      "         -0.5325, -0.7019, -0.6813, -0.9992,  0.4352,  0.5594, -0.3176,  0.6317,\n",
      "         -0.5097, -0.9699,  0.5408, -0.5417,  0.6882, -0.5613, -0.9999, -0.6752,\n",
      "         -0.8950, -0.6237,  0.5450, -0.6474,  0.6165, -0.5778, -1.0000, -0.3299,\n",
      "          0.4772, -0.9755,  0.6563, -0.9908,  0.4970,  0.9999,  1.0000, -0.9309,\n",
      "          0.5245, -0.9981, -0.5973, -0.6928, -1.0000,  0.5746,  1.0000,  0.7874,\n",
      "          0.4824, -0.9958, -0.9598,  0.9957, -0.9904, -0.6838,  0.5736, -0.5372,\n",
      "         -0.9996,  0.8443,  0.6096,  0.6239,  0.6185, -0.9927, -0.6150,  0.4123,\n",
      "         -0.9988,  0.5088,  0.9972, -0.5270,  0.5174,  0.2681, -0.9984,  0.6499]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "text = \"the cat is so sad .\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828526b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8256b4ba524ea1ba997b7be2eb0c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token     token_str                     sequence\n",
      "0  0.281033  10901          cute          the cat is so cute.\n",
      "1  0.094896  26354      adorable      the cat is so adorable.\n",
      "2  0.042963   1700         happy         the cat is so happy.\n",
      "3  0.040976   5066         funny         the cat is so funny.\n",
      "4  0.024234  28803  affectionate  the cat is so affectionate.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fillmask = pipeline('fill-mask', model='albert-base-v2')\n",
    "res = pd.DataFrame(fillmask(\"The cat is so [MASK] .\"))\n",
    "\n",
    "\n",
    "print(  res   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c575bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token   token_str                          sequence\n",
      "0  0.031417  27668  figurative  el chapo is a figurative person.\n",
      "1  0.028689  18496  franciscan  el chapo is a franciscan person.\n",
      "2  0.025276   9650   dominican   el chapo is a dominican person.\n",
      "3  0.022960  19210    moroccan    el chapo is a moroccan person.\n",
      "4  0.017772  14484      basque      el chapo is a basque person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res1 = pd.DataFrame(fillmask(\"El chapo is a  [MASK] person.\"))\n",
    "print(  res1   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c238ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token  token_str                     sequence\n",
      "0  0.059892   5934  wonderful  anna is a wonderful person.\n",
      "1  0.057768   5066      funny      anna is a funny person.\n",
      "2  0.047015    254       good       anna is a good person.\n",
      "3  0.046512   8601     lovely     anna is a lovely person.\n",
      "4  0.038440   2210       nice       anna is a nice person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res2 = pd.DataFrame(fillmask(\"Anna is a  [MASK] person.\"))\n",
    "print(  res2   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80897c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token  token_str                        sequence\n",
      "0  0.090353   5934  wonderful  michael is a wonderful person.\n",
      "1  0.056277    254       good       michael is a good person.\n",
      "2  0.054211   5066      funny      michael is a funny person.\n",
      "3  0.051298    374      great      michael is a great person.\n",
      "4  0.049223   2210       nice       michael is a nice person.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"Michael is a  [MASK] person.\"))\n",
    "print(  res3   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6332717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token token_str  \\\n",
      "0  0.416077     39       she   \n",
      "1  0.227181  28153     joyah   \n",
      "2  0.140533  29833    evalle   \n",
      "3  0.007875     24        he   \n",
      "4  0.003686  23512  jaenelle   \n",
      "\n",
      "                                            sequence  \n",
      "0  the nurse is examining the patient. she is wri...  \n",
      "1  the nurse is examining the patient. joyah is w...  \n",
      "2  the nurse is examining the patient. evalle is ...  \n",
      "3  the nurse is examining the patient. he is writ...  \n",
      "4  the nurse is examining the patient. jaenelle i...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"The nurse is examining the patient.  [MASK] is writing down notes.\"))\n",
    "print(  res3   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d88f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  token token_str  \\\n",
      "0  0.210027     24        he   \n",
      "1  0.208615     39       she   \n",
      "2  0.108849  28153     joyah   \n",
      "3  0.071829  29833    evalle   \n",
      "4  0.010178   1687    doctor   \n",
      "\n",
      "                                            sequence  \n",
      "0  the doctor is examining the patient. he is wri...  \n",
      "1  the doctor is examining the patient. she is wr...  \n",
      "2  the doctor is examining the patient. joyah is ...  \n",
      "3  the doctor is examining the patient. evalle is...  \n",
      "4  the doctor is examining the patient. doctor is...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = pd.DataFrame(fillmask(\"The doctor is examining the patient.  [MASK] is writing down notes.\"))\n",
    "print(  res3   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92730cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a750f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ee769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697003b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
